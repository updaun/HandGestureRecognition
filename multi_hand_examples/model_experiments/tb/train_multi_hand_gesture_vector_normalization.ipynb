{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**벡터 정규화**  \n",
    "벡터 정규화란 한 벡터를 벡터의 길이로 나누어서 그 벡터의 길이를 1로 만드는 것입니다. 이렇게 길이가 1이 된 벡터를 단위 벡터라고 부릅니다. 주로 키보드로 조작하는 게임에 자주 사용하는 정규화 방식으로 (1,0) 벡터와 (0,1) 벡터가 합쳐졌을 때 (1,1) 벡터의 길이가 루트2로 1보다 더 크기 때문에 이를 정규화를 통해 이 길이를 1로 맞춰주어야 하기 때문입니다. 속력과 방향을 정의되는 벡터에서 순수하게 방향만을 남겨서 사용하고자 할 때 위와 같은 벡터 정규화 개념을 사용합니다.\n",
    "\n",
    "벡터 정규화를 하는 방법은 각 성분(x, y, z)에 벡터의 길이를 나누는 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(711, 10, 111)\n",
      "(718, 10, 111)\n",
      "(1072, 10, 111)\n",
      "(1139, 10, 111)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data_yes = np.load('vector_normalization/train/seq_yes.npy')\n",
    "data_no = np.load('vector_normalization/train/seq_no.npy')\n",
    "data_like = np.load('vector_normalization/train/seq_like.npy')\n",
    "data_heart = np.load('vector_normalization/train/seq_heart.npy')\n",
    "\n",
    "print(data_yes.shape)\n",
    "print(data_no.shape)\n",
    "print(data_like.shape)\n",
    "print(data_heart.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_yes = np.load('vector_normalization/new_test/seq_yes.npy')\n",
    "test_no = np.load('vector_normalization/new_test/seq_no.npy')\n",
    "test_like = np.load('vector_normalization/new_test/seq_like.npy')\n",
    "test_heart = np.load('vector_normalization/new_test/seq_heart.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "yj5RmQfk2kBr",
    "outputId": "5df05e1b-f608-4d0b-ab5b-faf039a13b07",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3640, 10, 111), (3933, 10, 111))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions = ['yes', 'no', 'like', 'heart']\n",
    "\n",
    "data = np.concatenate([data_yes ,data_no, data_like, data_heart], axis=0)\n",
    "data_te = np.concatenate([test_yes ,test_no, test_like, test_heart], axis=0)\n",
    "\n",
    "data.shape, data_te.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BX0KTjeL2kBt"
   },
   "source": [
    "#### 데이터 x, y 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "w0ls_ie02kBw",
    "outputId": "34adde1d-5a76-4f6a-b47d-33c09a36edbe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3640, 10, 110)\n",
      "(3640,)\n",
      "\n",
      "(3933, 10, 110)\n",
      "(3933,)\n"
     ]
    }
   ],
   "source": [
    "x_data = data[:, :, :-1]\n",
    "labels = data[:, 0, -1]\n",
    "\n",
    "x_data_te = data_te[:, :, :-1]\n",
    "labels_te = data_te[:, 0, -1]\n",
    "\n",
    "print(x_data.shape)\n",
    "print(labels.shape)\n",
    "print()\n",
    "print(x_data_te.shape)\n",
    "print(labels_te.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "J0Sn2fkipSMN",
    "outputId": "73c64cad-de05-49ee-8444-835c3703dbd7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 1., 2., 3.]), array([0., 1., 2., 3.]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(labels), np.unique(labels_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "AvyeJuOZ2kBy",
    "outputId": "fb265eed-f81f-4735-95f8-3e341ce0ea83"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3640, 4), (3933, 4))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "y_data = to_categorical(labels, num_classes=len(actions))\n",
    "y_data_te = to_categorical(labels_te, num_classes=len(actions))\n",
    "\n",
    "y_data.shape, y_data_te.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E51SRxK_2kB7"
   },
   "source": [
    "#### X,y train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "piB6zMd82kCA",
    "outputId": "7055903d-b0e0-42c2-a491-d7c8faf525f0",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2730, 10, 110) (2730, 4)\n",
      "(910, 10, 110) (910, 4)\n",
      "(3933, 10, 110) (3933, 4)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "np.random.seed(1)\n",
    "\n",
    "x_data = x_data.astype(np.float32)\n",
    "y_data = y_data.astype(np.float32)\n",
    "\n",
    "x_data_te = x_data_te.astype(np.float32)\n",
    "y_data_te = y_data_te.astype(np.float32)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_data, y_data, test_size=0.25, random_state=42)\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_val.shape, y_val.shape)\n",
    "print(x_data_te.shape, y_data_te.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nh5A7V9hpSMW"
   },
   "source": [
    "#### 판단 척도\n",
    "\n",
    "판단 척도는 **F1 score**를 사용하였습니다. **F1 score**는 정밀도와 재현율을 결합한 지표로 정밀도와 재현율이 어느 한 쪽으로 치우치지 않을 때 높은 값을 나타냅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "-3GotKcppSMX"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "def metric_F1score(y_true,y_pred): \n",
    "    TP=tf.reduce_sum(y_true*tf.round(y_pred))\n",
    "    TN=tf.reduce_sum((1-y_true)*(1-tf.round(y_pred)))\n",
    "    FP=tf.reduce_sum((1-y_true)*tf.round(y_pred))\n",
    "    FN=tf.reduce_sum(y_true*(1-tf.round(y_pred)))\n",
    "    precision=TP/(TP+FP)\n",
    "    recall=TP/(TP+FN)\n",
    "    F1score=2*precision*recall/(precision+recall)\n",
    "    return F1score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pM3_ekVq2kCC"
   },
   "source": [
    "####  Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "BXDy5Yce2kCE",
    "outputId": "9651f411-da51-40c5-db68-8f01904152d9",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 64)                44800     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4)                 132       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 47,012\n",
      "Trainable params: 47,012\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "model = Sequential([\n",
    "    LSTM(64, activation='relu', input_shape=x_train.shape[1:3]),\n",
    "    Dropout(0.2),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(len(actions), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[metric_F1score])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FfZl6Yri2kCF"
   },
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "oU2EUK-62kCF",
    "outputId": "0ff6b74b-5831-4736-efea-d54844a4a5f7",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "85/86 [============================>.] - ETA: 0s - loss: 10.4170 - metric_F1score: 0.5072\n",
      "Epoch 00001: val_metric_F1score improved from inf to 0.84709, saving model to models\\vector_normalization_classifier.h5\n",
      "86/86 [==============================] - 7s 26ms/step - loss: 10.3887 - metric_F1score: 0.5111 - val_loss: 0.7562 - val_metric_F1score: 0.8471 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "85/86 [============================>.] - ETA: 0s - loss: 1.6364 - metric_F1score: 0.7818\n",
      "Epoch 00002: val_metric_F1score did not improve from 0.84709\n",
      "86/86 [==============================] - 2s 23ms/step - loss: 1.6329 - metric_F1score: 0.7820 - val_loss: 0.1721 - val_metric_F1score: 0.9545 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "85/86 [============================>.] - ETA: 0s - loss: 0.6754 - metric_F1score: 0.8877\n",
      "Epoch 00003: val_metric_F1score did not improve from 0.84709\n",
      "86/86 [==============================] - 2s 23ms/step - loss: 0.6729 - metric_F1score: 0.8890 - val_loss: 0.1012 - val_metric_F1score: 0.9816 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "86/86 [==============================] - ETA: 0s - loss: 0.3523 - metric_F1score: 0.9290\n",
      "Epoch 00004: val_metric_F1score did not improve from 0.84709\n",
      "86/86 [==============================] - 2s 23ms/step - loss: 0.3523 - metric_F1score: 0.9290 - val_loss: 0.0603 - val_metric_F1score: 0.9892 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "84/86 [============================>.] - ETA: 0s - loss: 0.2551 - metric_F1score: 0.9490\n",
      "Epoch 00005: val_metric_F1score did not improve from 0.84709\n",
      "86/86 [==============================] - 2s 23ms/step - loss: 0.2672 - metric_F1score: 0.9479 - val_loss: 0.0261 - val_metric_F1score: 0.9941 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "85/86 [============================>.] - ETA: 0s - loss: 0.1172 - metric_F1score: 0.9672\n",
      "Epoch 00006: val_metric_F1score did not improve from 0.84709\n",
      "86/86 [==============================] - 2s 23ms/step - loss: 0.1173 - metric_F1score: 0.9665 - val_loss: 0.0182 - val_metric_F1score: 0.9951 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "85/86 [============================>.] - ETA: 0s - loss: 0.0970 - metric_F1score: 0.9726\n",
      "Epoch 00007: val_metric_F1score did not improve from 0.84709\n",
      "86/86 [==============================] - 2s 23ms/step - loss: 0.0966 - metric_F1score: 0.9729 - val_loss: 0.0080 - val_metric_F1score: 0.9978 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "86/86 [==============================] - ETA: 0s - loss: 0.0893 - metric_F1score: 0.9769\n",
      "Epoch 00008: val_metric_F1score did not improve from 0.84709\n",
      "86/86 [==============================] - 2s 24ms/step - loss: 0.0893 - metric_F1score: 0.9769 - val_loss: 0.0179 - val_metric_F1score: 0.9957 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "84/86 [============================>.] - ETA: 0s - loss: 0.0898 - metric_F1score: 0.9761\n",
      "Epoch 00009: val_metric_F1score did not improve from 0.84709\n",
      "86/86 [==============================] - 2s 24ms/step - loss: 0.0887 - metric_F1score: 0.9763 - val_loss: 0.0075 - val_metric_F1score: 0.9978 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "84/86 [============================>.] - ETA: 0s - loss: 0.1054 - metric_F1score: 0.9825\n",
      "Epoch 00010: val_metric_F1score did not improve from 0.84709\n",
      "86/86 [==============================] - 2s 25ms/step - loss: 0.1046 - metric_F1score: 0.9825 - val_loss: 0.0054 - val_metric_F1score: 0.9978 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "86/86 [==============================] - ETA: 0s - loss: 0.1150 - metric_F1score: 0.9816\n",
      "Epoch 00011: val_metric_F1score did not improve from 0.84709\n",
      "86/86 [==============================] - 2s 24ms/step - loss: 0.1150 - metric_F1score: 0.9816 - val_loss: 0.0107 - val_metric_F1score: 0.9968 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "85/86 [============================>.] - ETA: 0s - loss: 0.0639 - metric_F1score: 0.9828\n",
      "Epoch 00012: val_metric_F1score did not improve from 0.84709\n",
      "86/86 [==============================] - 2s 24ms/step - loss: 0.0636 - metric_F1score: 0.9830 - val_loss: 0.0072 - val_metric_F1score: 0.9968 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "86/86 [==============================] - ETA: 0s - loss: 0.0519 - metric_F1score: 0.9884\n",
      "Epoch 00013: val_metric_F1score did not improve from 0.84709\n",
      "86/86 [==============================] - 2s 25ms/step - loss: 0.0519 - metric_F1score: 0.9884 - val_loss: 0.0083 - val_metric_F1score: 0.9968 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "84/86 [============================>.] - ETA: 0s - loss: 0.0360 - metric_F1score: 0.9914\n",
      "Epoch 00014: val_metric_F1score did not improve from 0.84709\n",
      "86/86 [==============================] - 2s 26ms/step - loss: 0.0354 - metric_F1score: 0.9916 - val_loss: 0.0054 - val_metric_F1score: 0.9973 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "85/86 [============================>.] - ETA: 0s - loss: 0.0252 - metric_F1score: 0.9934\n",
      "Epoch 00015: val_metric_F1score did not improve from 0.84709\n",
      "86/86 [==============================] - 2s 23ms/step - loss: 0.0251 - metric_F1score: 0.9934 - val_loss: 0.0041 - val_metric_F1score: 0.9978 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "84/86 [============================>.] - ETA: 0s - loss: 0.0282 - metric_F1score: 0.9922\n",
      "Epoch 00016: val_metric_F1score did not improve from 0.84709\n",
      "86/86 [==============================] - 2s 23ms/step - loss: 0.0278 - metric_F1score: 0.9924 - val_loss: 0.0021 - val_metric_F1score: 0.9989 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "85/86 [============================>.] - ETA: 0s - loss: 0.0147 - metric_F1score: 0.9952\n",
      "Epoch 00017: val_metric_F1score did not improve from 0.84709\n",
      "86/86 [==============================] - 2s 23ms/step - loss: 0.0155 - metric_F1score: 0.9941 - val_loss: 0.0011 - val_metric_F1score: 0.9995 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "84/86 [============================>.] - ETA: 0s - loss: 0.0380 - metric_F1score: 0.9914\n",
      "Epoch 00018: val_metric_F1score did not improve from 0.84709\n",
      "86/86 [==============================] - 2s 23ms/step - loss: 0.0375 - metric_F1score: 0.9916 - val_loss: 1.2186e-04 - val_metric_F1score: 1.0000 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "84/86 [============================>.] - ETA: 0s - loss: 0.0239 - metric_F1score: 0.9946\n",
      "Epoch 00019: val_metric_F1score did not improve from 0.84709\n",
      "86/86 [==============================] - 2s 23ms/step - loss: 0.0238 - metric_F1score: 0.9944 - val_loss: 5.8015e-04 - val_metric_F1score: 1.0000 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "85/86 [============================>.] - ETA: 0s - loss: 0.0169 - metric_F1score: 0.9950\n",
      "Epoch 00020: val_metric_F1score did not improve from 0.84709\n",
      "86/86 [==============================] - 2s 23ms/step - loss: 0.0169 - metric_F1score: 0.9951 - val_loss: 2.3904e-06 - val_metric_F1score: 1.0000 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "85/86 [============================>.] - ETA: 0s - loss: 0.0246 - metric_F1score: 0.9961\n",
      "Epoch 00021: val_metric_F1score did not improve from 0.84709\n",
      "86/86 [==============================] - 2s 23ms/step - loss: 0.0245 - metric_F1score: 0.9962 - val_loss: 7.4347e-04 - val_metric_F1score: 1.0000 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "85/86 [============================>.] - ETA: 0s - loss: 0.0192 - metric_F1score: 0.9971\n",
      "Epoch 00022: val_metric_F1score did not improve from 0.84709\n",
      "86/86 [==============================] - 2s 23ms/step - loss: 0.0191 - metric_F1score: 0.9971 - val_loss: 1.5982e-08 - val_metric_F1score: 1.0000 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "85/86 [============================>.] - ETA: 0s - loss: 0.0137 - metric_F1score: 0.9960\n",
      "Epoch 00023: val_metric_F1score did not improve from 0.84709\n",
      "86/86 [==============================] - 2s 23ms/step - loss: 0.0137 - metric_F1score: 0.9960 - val_loss: 1.7030e-08 - val_metric_F1score: 1.0000 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "85/86 [============================>.] - ETA: 0s - loss: 0.0186 - metric_F1score: 0.9971\n",
      "Epoch 00024: val_metric_F1score did not improve from 0.84709\n",
      "86/86 [==============================] - 2s 23ms/step - loss: 0.0185 - metric_F1score: 0.9971 - val_loss: 0.0838 - val_metric_F1score: 0.9957 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "86/86 [==============================] - ETA: 0s - loss: 0.0223 - metric_F1score: 0.9962\n",
      "Epoch 00025: val_metric_F1score did not improve from 0.84709\n",
      "86/86 [==============================] - 2s 24ms/step - loss: 0.0223 - metric_F1score: 0.9962 - val_loss: 2.4115e-07 - val_metric_F1score: 1.0000 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "84/86 [============================>.] - ETA: 0s - loss: 0.0226 - metric_F1score: 0.9970\n",
      "Epoch 00026: val_metric_F1score did not improve from 0.84709\n",
      "86/86 [==============================] - 2s 23ms/step - loss: 0.0222 - metric_F1score: 0.9971 - val_loss: 9.5405e-07 - val_metric_F1score: 1.0000 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/50\n",
      "86/86 [==============================] - ETA: 0s - loss: 0.0361 - metric_F1score: 0.9944\n",
      "Epoch 00027: val_metric_F1score did not improve from 0.84709\n",
      "86/86 [==============================] - 2s 23ms/step - loss: 0.0361 - metric_F1score: 0.9944 - val_loss: 0.0200 - val_metric_F1score: 0.9989 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "85/86 [============================>.] - ETA: 0s - loss: 0.1193 - metric_F1score: 0.9899\n",
      "Epoch 00028: val_metric_F1score did not improve from 0.84709\n",
      "86/86 [==============================] - 2s 23ms/step - loss: 0.1188 - metric_F1score: 0.9900 - val_loss: 0.0063 - val_metric_F1score: 0.9978 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "84/86 [============================>.] - ETA: 0s - loss: 0.0231 - metric_F1score: 0.9952\n",
      "Epoch 00029: val_metric_F1score did not improve from 0.84709\n",
      "86/86 [==============================] - 2s 23ms/step - loss: 0.0228 - metric_F1score: 0.9953 - val_loss: 0.0011 - val_metric_F1score: 0.9989 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "85/86 [============================>.] - ETA: 0s - loss: 0.0047 - metric_F1score: 0.9982\n",
      "Epoch 00030: val_metric_F1score did not improve from 0.84709\n",
      "86/86 [==============================] - 2s 23ms/step - loss: 0.0047 - metric_F1score: 0.9982 - val_loss: 0.0012 - val_metric_F1score: 0.9989 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "85/86 [============================>.] - ETA: 0s - loss: 0.0044 - metric_F1score: 0.9987\n",
      "Epoch 00031: val_metric_F1score did not improve from 0.84709\n",
      "86/86 [==============================] - 2s 23ms/step - loss: 0.0044 - metric_F1score: 0.9987 - val_loss: 0.0013 - val_metric_F1score: 0.9989 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "85/86 [============================>.] - ETA: 0s - loss: 0.0021 - metric_F1score: 0.9993\n",
      "Epoch 00032: val_metric_F1score did not improve from 0.84709\n",
      "86/86 [==============================] - 2s 23ms/step - loss: 0.0021 - metric_F1score: 0.9993 - val_loss: 2.0315e-04 - val_metric_F1score: 1.0000 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "84/86 [============================>.] - ETA: 0s - loss: 0.0131 - metric_F1score: 0.9974\n",
      "Epoch 00033: val_metric_F1score did not improve from 0.84709\n",
      "86/86 [==============================] - 2s 23ms/step - loss: 0.0129 - metric_F1score: 0.9975 - val_loss: 1.2004e-04 - val_metric_F1score: 1.0000 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "85/86 [============================>.] - ETA: 0s - loss: 0.0415 - metric_F1score: 0.9952\n",
      "Epoch 00034: val_metric_F1score did not improve from 0.84709\n",
      "86/86 [==============================] - 2s 25ms/step - loss: 0.0414 - metric_F1score: 0.9953 - val_loss: 8.3976e-05 - val_metric_F1score: 1.0000 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "85/86 [============================>.] - ETA: 0s - loss: 0.0378 - metric_F1score: 0.9943\n",
      "Epoch 00035: val_metric_F1score did not improve from 0.84709\n",
      "86/86 [==============================] - 2s 24ms/step - loss: 0.0377 - metric_F1score: 0.9944 - val_loss: 0.0874 - val_metric_F1score: 0.9978 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "85/86 [============================>.] - ETA: 0s - loss: 0.0354 - metric_F1score: 0.9915\n",
      "Epoch 00036: val_metric_F1score did not improve from 0.84709\n",
      "86/86 [==============================] - 2s 24ms/step - loss: 0.0353 - metric_F1score: 0.9916 - val_loss: 2.6593e-08 - val_metric_F1score: 1.0000 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "85/86 [============================>.] - ETA: 0s - loss: 0.0120 - metric_F1score: 0.9967\n",
      "Epoch 00037: val_metric_F1score did not improve from 0.84709\n",
      "86/86 [==============================] - 3s 29ms/step - loss: 0.0120 - metric_F1score: 0.9967 - val_loss: 5.5846e-05 - val_metric_F1score: 1.0000 - lr: 0.0010\n",
      "Epoch 38/50\n",
      "85/86 [============================>.] - ETA: 0s - loss: 0.0119 - metric_F1score: 0.9963\n",
      "Epoch 00038: val_metric_F1score did not improve from 0.84709\n",
      "86/86 [==============================] - 3s 35ms/step - loss: 0.0118 - metric_F1score: 0.9964 - val_loss: 1.9519e-08 - val_metric_F1score: 1.0000 - lr: 0.0010\n",
      "Epoch 39/50\n",
      "85/86 [============================>.] - ETA: 0s - loss: 0.0090 - metric_F1score: 0.9980\n",
      "Epoch 00039: val_metric_F1score did not improve from 0.84709\n",
      "86/86 [==============================] - 3s 30ms/step - loss: 0.0089 - metric_F1score: 0.9980 - val_loss: 2.8034e-08 - val_metric_F1score: 1.0000 - lr: 0.0010\n",
      "Epoch 40/50\n",
      "85/86 [============================>.] - ETA: 0s - loss: 0.0044 - metric_F1score: 0.9993  \n",
      "Epoch 00040: val_metric_F1score did not improve from 0.84709\n",
      "86/86 [==============================] - 3s 30ms/step - loss: 0.0044 - metric_F1score: 0.9993 - val_loss: 9.5102e-08 - val_metric_F1score: 1.0000 - lr: 0.0010\n",
      "Epoch 41/50\n",
      "84/86 [============================>.] - ETA: 0s - loss: 2.5865e-04 - metric_F1score: 1.0000\n",
      "Epoch 00041: val_metric_F1score did not improve from 0.84709\n",
      "86/86 [==============================] - 3s 30ms/step - loss: 2.9157e-04 - metric_F1score: 1.0000 - val_loss: 1.0218e-08 - val_metric_F1score: 1.0000 - lr: 0.0010\n",
      "Epoch 42/50\n",
      "85/86 [============================>.] - ETA: 0s - loss: 0.0080 - metric_F1score: 0.9983\n",
      "Epoch 00042: val_metric_F1score did not improve from 0.84709\n",
      "86/86 [==============================] - 3s 30ms/step - loss: 0.0079 - metric_F1score: 0.9984 - val_loss: 7.2200e-06 - val_metric_F1score: 1.0000 - lr: 0.0010\n",
      "Epoch 43/50\n",
      "85/86 [============================>.] - ETA: 0s - loss: 0.0047 - metric_F1score: 0.9985\n",
      "Epoch 00043: val_metric_F1score did not improve from 0.84709\n",
      "86/86 [==============================] - 3s 31ms/step - loss: 0.0047 - metric_F1score: 0.9985 - val_loss: 1.4006e-05 - val_metric_F1score: 1.0000 - lr: 0.0010\n",
      "Epoch 44/50\n",
      "85/86 [============================>.] - ETA: 0s - loss: 0.0045 - metric_F1score: 0.9980\n",
      "Epoch 00044: val_metric_F1score did not improve from 0.84709\n",
      "86/86 [==============================] - 3s 31ms/step - loss: 0.0045 - metric_F1score: 0.9980 - val_loss: 1.6197e-06 - val_metric_F1score: 1.0000 - lr: 0.0010\n",
      "Epoch 45/50\n",
      "85/86 [============================>.] - ETA: 0s - loss: 0.0030 - metric_F1score: 0.9994\n",
      "Epoch 00045: val_metric_F1score did not improve from 0.84709\n",
      "86/86 [==============================] - 3s 31ms/step - loss: 0.0030 - metric_F1score: 0.9995 - val_loss: 1.3016e-04 - val_metric_F1score: 1.0000 - lr: 0.0010\n",
      "Epoch 46/50\n",
      "86/86 [==============================] - ETA: 0s - loss: 0.0033 - metric_F1score: 0.9993\n",
      "Epoch 00046: val_metric_F1score did not improve from 0.84709\n",
      "86/86 [==============================] - 3s 32ms/step - loss: 0.0033 - metric_F1score: 0.9993 - val_loss: 1.2326e-07 - val_metric_F1score: 1.0000 - lr: 0.0010\n",
      "Epoch 47/50\n",
      "85/86 [============================>.] - ETA: 0s - loss: 0.0053 - metric_F1score: 0.9993\n",
      "Epoch 00047: val_metric_F1score did not improve from 0.84709\n",
      "86/86 [==============================] - 3s 37ms/step - loss: 0.0053 - metric_F1score: 0.9993 - val_loss: 2.3056e-08 - val_metric_F1score: 1.0000 - lr: 0.0010\n",
      "Epoch 48/50\n",
      "85/86 [============================>.] - ETA: 0s - loss: 0.0259 - metric_F1score: 0.9976\n",
      "Epoch 00048: val_metric_F1score did not improve from 0.84709\n",
      "86/86 [==============================] - 3s 37ms/step - loss: 0.0258 - metric_F1score: 0.9976 - val_loss: 0.0054 - val_metric_F1score: 0.9989 - lr: 0.0010\n",
      "Epoch 49/50\n",
      "85/86 [============================>.] - ETA: 0s - loss: 0.0069 - metric_F1score: 0.9978\n",
      "Epoch 00049: val_metric_F1score did not improve from 0.84709\n",
      "86/86 [==============================] - 3s 31ms/step - loss: 0.0069 - metric_F1score: 0.9978 - val_loss: 1.3866e-06 - val_metric_F1score: 1.0000 - lr: 0.0010\n",
      "Epoch 50/50\n",
      "85/86 [============================>.] - ETA: 0s - loss: 0.0016 - metric_F1score: 0.9996\n",
      "Epoch 00050: val_metric_F1score did not improve from 0.84709\n",
      "86/86 [==============================] - 3s 33ms/step - loss: 0.0016 - metric_F1score: 0.9996 - val_loss: 3.8775e-08 - val_metric_F1score: 1.0000 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    validation_data=(x_val, y_val),\n",
    "    epochs=50,\n",
    "    callbacks=[\n",
    "        ModelCheckpoint('models/vector_normalization_classifier.h5', monitor='val_metric_F1score', verbose=1, save_best_only=True, mode='auto'),\n",
    "        ReduceLROnPlateau(monitor='val_metric_F1score', factor=0.5, patience=50, verbose=1, mode='auto')\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "ryE9NZb02kCJ",
    "outputId": "9d2b1407-5964-426f-c98f-2dca01c9ccd8"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, loss_ax = plt.subplots(figsize=(16, 10))\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "\n",
    "acc_ax.plot(history.history['metric_F1score'], 'b', label='train f1')\n",
    "acc_ax.plot(history.history['val_metric_F1score'], 'g', label='val f1')\n",
    "acc_ax.set_ylabel('f1-score')\n",
    "acc_ax.legend(loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6KI1GHvY2kCJ"
   },
   "source": [
    "####  Results Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model('models/vector_normalization_classifier.h5', custom_objects = {'metric_F1score':metric_F1score})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "6SnjKeNw2kCL",
    "outputId": "f63b7009-913c-406c-e523-08c88c231f58"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[703,  14],\n",
       "        [ 46, 147]],\n",
       "\n",
       "       [[705,  17],\n",
       "        [ 51, 137]],\n",
       "\n",
       "       [[592,  60],\n",
       "        [ 20, 238]],\n",
       "\n",
       "       [[588,  51],\n",
       "        [ 25, 246]]], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "y_pred = model.predict(x_val)\n",
    "multilabel_confusion_matrix(np.argmax(y_val, axis=1), np.argmax(y_pred, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.76      0.83       193\n",
      "           1       0.89      0.73      0.80       188\n",
      "           2       0.80      0.92      0.86       258\n",
      "           3       0.83      0.91      0.87       271\n",
      "\n",
      "    accuracy                           0.84       910\n",
      "   macro avg       0.86      0.83      0.84       910\n",
      "weighted avg       0.85      0.84      0.84       910\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(np.argmax(y_val, axis=1), np.argmax(y_pred, axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test data로 모델 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.6678413e-02, 8.4249437e-02, 1.6021604e-02, 8.0305058e-01],\n",
       "       [4.1810136e-02, 3.1565867e-02, 5.9916116e-03, 9.2063236e-01],\n",
       "       [2.6559686e-02, 4.9321852e-03, 7.3336856e-04, 9.6777481e-01],\n",
       "       ...,\n",
       "       [2.2740485e-11, 3.2241365e-12, 9.9703252e-01, 2.9675148e-03],\n",
       "       [2.3038800e-10, 1.5812891e-10, 9.8987329e-01, 1.0126760e-02],\n",
       "       [1.4360139e-09, 2.6245001e-10, 9.8822355e-01, 1.1776412e-02]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(x_data_te);pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[2869,   43],\n",
       "        [ 417,  604]],\n",
       "\n",
       "       [[3153,   87],\n",
       "        [ 106,  587]],\n",
       "\n",
       "       [[2472,  368],\n",
       "        [ 146,  947]],\n",
       "\n",
       "       [[2443,  364],\n",
       "        [ 193,  933]]], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "\n",
    "multilabel_confusion_matrix(np.argmax(y_data_te, axis=1), np.argmax(pred, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.59      0.72      1021\n",
      "           1       0.87      0.85      0.86       693\n",
      "           2       0.72      0.87      0.79      1093\n",
      "           3       0.72      0.83      0.77      1126\n",
      "\n",
      "    accuracy                           0.78      3933\n",
      "   macro avg       0.81      0.78      0.78      3933\n",
      "weighted avg       0.80      0.78      0.78      3933\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(np.argmax(y_data_te, axis=1), np.argmax(pred, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.7763983>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_F1score(y_data_te, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\hites\\AppData\\Local\\Temp\\tmphc55gmre\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\hites\\AppData\\Local\\Temp\\tmphc55gmre\\assets\n"
     ]
    },
    {
     "ename": "ConverterError",
     "evalue": "C:\\Users\\hites\\anaconda3\\lib\\site-packages\\tensorflow\\python\\saved_model\\save.py:1315:0: error: 'tf.TensorListReserve' op requires element_shape to be static during TF Lite transformation pass\n<unknown>:0: note: loc(\"StatefulPartitionedCall\"): called from\nC:\\Users\\hites\\anaconda3\\lib\\site-packages\\tensorflow\\python\\saved_model\\save.py:1315:0: error: failed to legalize operation 'tf.TensorListReserve' that was explicitly marked illegal\n<unknown>:0: note: loc(\"StatefulPartitionedCall\"): called from\n<unknown>:0: error: Lowering tensor list ops is failed. Please consider using Select TF ops and disabling `_experimental_lower_tensor_list_ops` flag in the TFLite converter object. For example, converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\\n converter._experimental_lower_tensor_list_ops = False\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mConverterError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-47361ccaf0d3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# Convert the model.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mconverter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTFLiteConverter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_keras_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mtflite_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconverter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# Save the model.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\lite\\python\\lite.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    773\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    774\u001b[0m     \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 775\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convert_and_export_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconvert_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    776\u001b[0m     \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    777\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\lite\\python\\lite.py\u001b[0m in \u001b[0;36m_convert_and_export_metrics\u001b[1;34m(self, convert_func, *args, **kwargs)\u001b[0m\n\u001b[0;32m    759\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_save_conversion_params_metric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    760\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 761\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    762\u001b[0m     \u001b[0melapsed_time_ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    763\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\lite\\python\\lite.py\u001b[0m in \u001b[0;36mconvert\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1168\u001b[0m         \u001b[0mInvalid\u001b[0m \u001b[0mquantization\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1169\u001b[0m     \"\"\"\n\u001b[1;32m-> 1170\u001b[1;33m     \u001b[0msaved_model_convert_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convert_as_saved_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1171\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msaved_model_convert_result\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1172\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0msaved_model_convert_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\lite\\python\\lite.py\u001b[0m in \u001b[0;36m_convert_as_saved_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1151\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaved_model_dir\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1152\u001b[0m         return super(TFLiteKerasModelConverterV2,\n\u001b[1;32m-> 1153\u001b[1;33m                      self).convert(graph_def, input_tensors, output_tensors)\n\u001b[0m\u001b[0;32m   1154\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1155\u001b[0m       \u001b[0mshutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrmtree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\lite\\python\\lite.py\u001b[0m in \u001b[0;36mconvert\u001b[1;34m(self, graph_def, input_tensors, output_tensors)\u001b[0m\n\u001b[0;32m    947\u001b[0m         \u001b[0minput_tensors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    948\u001b[0m         \u001b[0moutput_tensors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_tensors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 949\u001b[1;33m         **converter_kwargs)\n\u001b[0m\u001b[0;32m    950\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    951\u001b[0m     return self._optimize_tflite_model(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\lite\\python\\convert_phase.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m           \u001b[0mreport_error_message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconverter_error\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 223\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mconverter_error\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m  \u001b[1;31m# Re-throws the exception.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    224\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m         \u001b[0mreport_error_message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\lite\\python\\convert_phase.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    217\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mConverterError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mconverter_error\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mconverter_error\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\lite\\python\\convert.py\u001b[0m in \u001b[0;36mtoco_convert_impl\u001b[1;34m(input_data, input_tensors, output_tensors, enable_mlir_converter, *args, **kwargs)\u001b[0m\n\u001b[0;32m    824\u001b[0m       \u001b[0minput_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    825\u001b[0m       \u001b[0mdebug_info_str\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdebug_info_str\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 826\u001b[1;33m       enable_mlir_converter=enable_mlir_converter)\n\u001b[0m\u001b[0;32m    827\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    828\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\lite\\python\\convert.py\u001b[0m in \u001b[0;36mtoco_convert_protos\u001b[1;34m(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)\u001b[0m\n\u001b[0;32m    313\u001b[0m       \u001b[1;32mfor\u001b[0m \u001b[0merror_data\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_metrics_wrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve_collected_errors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m         \u001b[0mconverter_error\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 315\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mconverter_error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    317\u001b[0m   return _run_toco_binary(model_flags_str, toco_flags_str, input_data_str,\n",
      "\u001b[1;31mConverterError\u001b[0m: C:\\Users\\hites\\anaconda3\\lib\\site-packages\\tensorflow\\python\\saved_model\\save.py:1315:0: error: 'tf.TensorListReserve' op requires element_shape to be static during TF Lite transformation pass\n<unknown>:0: note: loc(\"StatefulPartitionedCall\"): called from\nC:\\Users\\hites\\anaconda3\\lib\\site-packages\\tensorflow\\python\\saved_model\\save.py:1315:0: error: failed to legalize operation 'tf.TensorListReserve' that was explicitly marked illegal\n<unknown>:0: note: loc(\"StatefulPartitionedCall\"): called from\n<unknown>:0: error: Lowering tensor list ops is failed. Please consider using Select TF ops and disabling `_experimental_lower_tensor_list_ops` flag in the TFLite converter object. For example, converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\\n converter._experimental_lower_tensor_list_ops = False\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# Convert the model.\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the model.\n",
    "with open('models/vector_normalization_classifier.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "NovsrRN12kCW",
    "nsZLMbtO2kCY"
   ],
   "name": "train_multi_hand_gesture3.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "eb8d34d53d16442ab45ee5ae0fcb3a4f0af0f2ef684aa754f8ae5e8bd03f8c50"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
