{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\Desktop\\Projects\\Hand_Gesture_Recognition\n"
     ]
    }
   ],
   "source": [
    "%pwd\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1036, 10, 111)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions = ['yes', 'no', 'like', 'heart']\n",
    "\n",
    "data = np.concatenate([\n",
    "    np.load('dataset/seq_yes_1651849629.npy'),\n",
    "    np.load('dataset/seq_no_1651849629.npy'),\n",
    "    np.load('dataset/seq_like_1651849629.npy'),\n",
    "    np.load('dataset/seq_heart_1651849629.npy')\n",
    "], axis=0)\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1036, 10, 110)\n",
      "(1036,)\n"
     ]
    }
   ],
   "source": [
    "x_data = data[:, :, :-1]\n",
    "labels = data[:, 0, -1]\n",
    "\n",
    "print(x_data.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1036, 4)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "y_data = to_categorical(labels, num_classes=len(actions))\n",
    "y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(932, 10, 110) (932, 4)\n",
      "(104, 10, 110) (104, 4)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_data = x_data.astype(np.float32)\n",
    "y_data = y_data.astype(np.float32)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_data, y_data, test_size=0.1, random_state=42)\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 64)                44800     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4)                 132       \n",
      "=================================================================\n",
      "Total params: 47,012\n",
      "Trainable params: 47,012\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "model = Sequential([\n",
    "    LSTM(64, activation='relu', input_shape=x_train.shape[1:3]),\n",
    "    Dropout(0.2),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(len(actions), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "30/30 [==============================] - 2s 25ms/step - loss: 41.6751 - acc: 0.3118 - val_loss: 2.3043 - val_acc: 0.7596\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.75962, saving model to models\\multi_hand_gesture_classifier.h5\n",
      "Epoch 2/200\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 5.0859 - acc: 0.6719 - val_loss: 1.2273 - val_acc: 0.9135\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.75962 to 0.91346, saving model to models\\multi_hand_gesture_classifier.h5\n",
      "Epoch 3/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 2.0934 - acc: 0.8116 - val_loss: 0.3146 - val_acc: 0.9327\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.91346 to 0.93269, saving model to models\\multi_hand_gesture_classifier.h5\n",
      "Epoch 4/200\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 1.6947 - acc: 0.8409 - val_loss: 0.1966 - val_acc: 0.9519\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.93269 to 0.95192, saving model to models\\multi_hand_gesture_classifier.h5\n",
      "Epoch 5/200\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 1.1807 - acc: 0.8500 - val_loss: 0.0465 - val_acc: 0.9808\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.95192 to 0.98077, saving model to models\\multi_hand_gesture_classifier.h5\n",
      "Epoch 6/200\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.5915 - acc: 0.9012 - val_loss: 0.0175 - val_acc: 0.9904\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.98077 to 0.99038, saving model to models\\multi_hand_gesture_classifier.h5\n",
      "Epoch 7/200\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.4324 - acc: 0.9252 - val_loss: 0.0032 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.99038 to 1.00000, saving model to models\\multi_hand_gesture_classifier.h5\n",
      "Epoch 8/200\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.2385 - acc: 0.9558 - val_loss: 0.0089 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 1.00000\n",
      "Epoch 9/200\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.2616 - acc: 0.9410 - val_loss: 0.0063 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 1.00000\n",
      "Epoch 10/200\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.4037 - acc: 0.9283 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 1.00000\n",
      "Epoch 11/200\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.3625 - acc: 0.9409 - val_loss: 0.0057 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 1.00000\n",
      "Epoch 12/200\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.1580 - acc: 0.9515 - val_loss: 0.0079 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 1.00000\n",
      "Epoch 13/200\n",
      "30/30 [==============================] - 1s 18ms/step - loss: 0.2322 - acc: 0.9596 - val_loss: 8.2550e-04 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 1.00000\n",
      "Epoch 14/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.2368 - acc: 0.9616 - val_loss: 7.1648e-04 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 1.00000\n",
      "Epoch 15/200\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.0724 - acc: 0.9776 - val_loss: 1.7904e-04 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 1.00000\n",
      "Epoch 16/200\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.1047 - acc: 0.9751 - val_loss: 6.1553e-05 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 1.00000\n",
      "Epoch 17/200\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.0860 - acc: 0.9888 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 1.00000\n",
      "Epoch 18/200\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.1266 - acc: 0.9754 - val_loss: 1.0511e-06 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 1.00000\n",
      "Epoch 19/200\n",
      "30/30 [==============================] - 1s 22ms/step - loss: 0.0732 - acc: 0.9794 - val_loss: 1.0350e-06 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 1.00000\n",
      "Epoch 20/200\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.0934 - acc: 0.9716 - val_loss: 1.4754e-05 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 1.00000\n",
      "Epoch 21/200\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.0794 - acc: 0.9887 - val_loss: 2.8656e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 1.00000\n",
      "Epoch 22/200\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.0496 - acc: 0.9831 - val_loss: 2.8312e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 1.00000\n",
      "Epoch 23/200\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.0788 - acc: 0.9899 - val_loss: 8.6425e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 1.00000\n",
      "Epoch 24/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0752 - acc: 0.9788 - val_loss: 8.7456e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 1.00000\n",
      "Epoch 25/200\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.0454 - acc: 0.9895 - val_loss: 1.6677e-06 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 1.00000\n",
      "Epoch 26/200\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.0236 - acc: 0.9862 - val_loss: 1.9691e-06 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 1.00000\n",
      "Epoch 27/200\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.0216 - acc: 0.9947 - val_loss: 1.7869e-06 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 1.00000\n",
      "Epoch 28/200\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.0139 - acc: 0.9982 - val_loss: 7.8287e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 1.00000\n",
      "Epoch 29/200\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.0135 - acc: 0.9955 - val_loss: 9.7887e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 1.00000\n",
      "Epoch 30/200\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.0296 - acc: 0.9868 - val_loss: 1.3755e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 1.00000\n",
      "Epoch 31/200\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.0233 - acc: 0.9947 - val_loss: 1.5589e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 1.00000\n",
      "Epoch 32/200\n",
      "30/30 [==============================] - 0s 17ms/step - loss: 0.0268 - acc: 0.9892 - val_loss: 2.3269e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 1.00000\n",
      "Epoch 33/200\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.0261 - acc: 0.9920 - val_loss: 4.3213e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 1.00000\n",
      "Epoch 34/200\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.0270 - acc: 0.9901 - val_loss: 5.3872e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 1.00000\n",
      "Epoch 35/200\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.0131 - acc: 0.9971 - val_loss: 7.4160e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 1.00000\n",
      "Epoch 36/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.0218 - acc: 0.9925 - val_loss: 3.7940e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 1.00000\n",
      "Epoch 37/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.1195 - acc: 0.9959 - val_loss: 1.5780e-04 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 1.00000\n",
      "Epoch 38/200\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.1033 - acc: 0.9763 - val_loss: 3.6336e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 1.00000\n",
      "Epoch 39/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.0395 - acc: 0.9917 - val_loss: 3.6565e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 1.00000\n",
      "Epoch 40/200\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.0046 - acc: 0.9983 - val_loss: 4.6996e-08 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 1.00000\n",
      "Epoch 41/200\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.0313 - acc: 0.9934 - val_loss: 1.3858e-06 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 1.00000\n",
      "Epoch 42/200\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.0101 - acc: 0.9977 - val_loss: 6.1323e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 1.00000\n",
      "Epoch 43/200\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.0209 - acc: 0.9961 - val_loss: 4.5886e-06 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 1.00000\n",
      "Epoch 44/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0504 - acc: 0.9909 - val_loss: 1.1462e-08 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 1.00000\n",
      "Epoch 45/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0258 - acc: 0.9914 - val_loss: 5.7312e-09 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 1.00000\n",
      "Epoch 46/200\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.0106 - acc: 0.9959 - val_loss: 4.5850e-09 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 1.00000\n",
      "Epoch 47/200\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.0130 - acc: 0.9948 - val_loss: 3.4387e-09 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 1.00000\n",
      "Epoch 48/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0015 - acc: 0.9999 - val_loss: 3.4387e-09 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 1.00000\n",
      "Epoch 49/200\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.0106 - acc: 0.9939 - val_loss: 2.2925e-09 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 1.00000\n",
      "Epoch 50/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0024 - acc: 0.9993 - val_loss: 3.4387e-09 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 1.00000\n",
      "Epoch 51/200\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.0514 - acc: 0.9927 - val_loss: 9.1699e-09 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 1.00000\n",
      "Epoch 52/200\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.0109 - acc: 0.9975 - val_loss: 1.6047e-08 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 1.00000\n",
      "Epoch 53/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0043 - acc: 0.9984 - val_loss: 6.8775e-09 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 1.00000\n",
      "Epoch 54/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0065 - acc: 0.9951 - val_loss: 4.5850e-09 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 1.00000\n",
      "Epoch 55/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0040 - acc: 0.9975 - val_loss: 4.5850e-09 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 1.00000\n",
      "Epoch 56/200\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.0034 - acc: 0.9979 - val_loss: 3.4387e-09 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00056: val_acc did not improve from 1.00000\n",
      "Epoch 57/200\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.0067 - acc: 0.9967 - val_loss: 2.2925e-09 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 00057: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 58/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 3.4387e-09 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00058: val_acc did not improve from 1.00000\n",
      "Epoch 59/200\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.0163 - acc: 0.9969 - val_loss: 4.5850e-09 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 1.00000\n",
      "Epoch 60/200\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.0116 - acc: 0.9984 - val_loss: 2.1779e-08 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 1.00000\n",
      "Epoch 61/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.0017 - acc: 0.9996 - val_loss: 2.7510e-08 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00061: val_acc did not improve from 1.00000\n",
      "Epoch 62/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0073 - acc: 1.0000 - val_loss: 1.9486e-08 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00062: val_acc did not improve from 1.00000\n",
      "Epoch 63/200\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.0042 - acc: 0.9986 - val_loss: 1.8340e-08 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00063: val_acc did not improve from 1.00000\n",
      "Epoch 64/200\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.0040 - acc: 0.9992 - val_loss: 1.0316e-08 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 1.00000\n",
      "Epoch 65/200\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.0190 - acc: 0.9914 - val_loss: 3.4387e-09 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 1.00000\n",
      "Epoch 66/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.0061 - acc: 0.9954 - val_loss: 3.4387e-09 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00066: val_acc did not improve from 1.00000\n",
      "Epoch 67/200\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.0064 - acc: 0.9989 - val_loss: 2.2925e-09 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 1.00000\n",
      "Epoch 68/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0024 - acc: 0.9998 - val_loss: 1.1462e-09 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00068: val_acc did not improve from 1.00000\n",
      "Epoch 69/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 1.4100e-04 - acc: 1.0000 - val_loss: 2.2925e-09 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00069: val_acc did not improve from 1.00000\n",
      "Epoch 70/200\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.0029 - acc: 0.9988 - val_loss: 2.2925e-09 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00070: val_acc did not improve from 1.00000\n",
      "Epoch 71/200\n",
      "30/30 [==============================] - 0s 17ms/step - loss: 9.2444e-04 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00071: val_acc did not improve from 1.00000\n",
      "Epoch 72/200\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.0084 - acc: 0.9966 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00072: val_acc did not improve from 1.00000\n",
      "Epoch 73/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 1.4701e-04 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00073: val_acc did not improve from 1.00000\n",
      "Epoch 74/200\n",
      "30/30 [==============================] - 1s 18ms/step - loss: 0.0058 - acc: 0.9995 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00074: val_acc did not improve from 1.00000\n",
      "Epoch 75/200\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.0017 - acc: 0.9990 - val_loss: 1.1462e-09 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00075: val_acc did not improve from 1.00000\n",
      "Epoch 76/200\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 3.8060e-04 - acc: 1.0000 - val_loss: 4.5850e-09 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00076: val_acc did not improve from 1.00000\n",
      "Epoch 77/200\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.0029 - acc: 0.9973 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00077: val_acc did not improve from 1.00000\n",
      "Epoch 78/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0184 - acc: 0.9967 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00078: val_acc did not improve from 1.00000\n",
      "Epoch 79/200\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.0237 - acc: 0.9980 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00079: val_acc did not improve from 1.00000\n",
      "Epoch 80/200\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.0025 - acc: 0.9984 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00080: val_acc did not improve from 1.00000\n",
      "Epoch 81/200\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.0039 - acc: 0.9978 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00081: val_acc did not improve from 1.00000\n",
      "Epoch 82/200\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.0112 - acc: 0.9966 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00082: val_acc did not improve from 1.00000\n",
      "Epoch 83/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 6.4112e-04 - acc: 0.9996 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00083: val_acc did not improve from 1.00000\n",
      "Epoch 84/200\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.0027 - acc: 0.9979 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00084: val_acc did not improve from 1.00000\n",
      "Epoch 85/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 1.4268e-04 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00085: val_acc did not improve from 1.00000\n",
      "Epoch 86/200\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.0021 - acc: 0.9991 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00086: val_acc did not improve from 1.00000\n",
      "Epoch 87/200\n",
      "30/30 [==============================] - 1s 18ms/step - loss: 0.0015 - acc: 0.9988 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00087: val_acc did not improve from 1.00000\n",
      "Epoch 88/200\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.0030 - acc: 0.9978 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00088: val_acc did not improve from 1.00000\n",
      "Epoch 89/200\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.0288 - acc: 0.9955 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00089: val_acc did not improve from 1.00000\n",
      "Epoch 90/200\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.0024 - acc: 0.9992 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00090: val_acc did not improve from 1.00000\n",
      "Epoch 91/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.0022 - acc: 0.9984 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00091: val_acc did not improve from 1.00000\n",
      "Epoch 92/200\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.0173 - acc: 0.9965 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00092: val_acc did not improve from 1.00000\n",
      "Epoch 93/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 6.0752e-04 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00093: val_acc did not improve from 1.00000\n",
      "Epoch 94/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00094: val_acc did not improve from 1.00000\n",
      "Epoch 95/200\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.0171 - acc: 0.9956 - val_loss: 0.0106 - val_acc: 0.9904\n",
      "\n",
      "Epoch 00095: val_acc did not improve from 1.00000\n",
      "Epoch 96/200\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.1998 - acc: 0.9817 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00096: val_acc did not improve from 1.00000\n",
      "Epoch 97/200\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.0043 - acc: 0.9970 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00097: val_acc did not improve from 1.00000\n",
      "Epoch 98/200\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.0051 - acc: 0.9967 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00098: val_acc did not improve from 1.00000\n",
      "Epoch 99/200\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.0078 - acc: 0.9974 - val_loss: 9.4201e-05 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00099: val_acc did not improve from 1.00000\n",
      "Epoch 100/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.1444 - acc: 0.9906 - val_loss: 2.2810e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00100: val_acc did not improve from 1.00000\n",
      "Epoch 101/200\n",
      "30/30 [==============================] - 0s 17ms/step - loss: 5.3987e-04 - acc: 1.0000 - val_loss: 1.6047e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00101: val_acc did not improve from 1.00000\n",
      "Epoch 102/200\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.0104 - acc: 0.9964 - val_loss: 2.5332e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00102: val_acc did not improve from 1.00000\n",
      "Epoch 103/200\n",
      "30/30 [==============================] - 1s 18ms/step - loss: 0.0084 - acc: 0.9976 - val_loss: 4.4703e-08 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00103: val_acc did not improve from 1.00000\n",
      "Epoch 104/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 4.9378e-04 - acc: 1.0000 - val_loss: 1.2609e-08 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00104: val_acc did not improve from 1.00000\n",
      "Epoch 105/200\n",
      "30/30 [==============================] - 1s 18ms/step - loss: 0.0015 - acc: 0.9987 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00105: val_acc did not improve from 1.00000\n",
      "Epoch 106/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 2.3640e-04 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00106: val_acc did not improve from 1.00000\n",
      "Epoch 107/200\n",
      "30/30 [==============================] - 1s 18ms/step - loss: 6.7442e-04 - acc: 0.9997 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00107: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 00107: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 108/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 4.1215e-04 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00108: val_acc did not improve from 1.00000\n",
      "Epoch 109/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.0013 - acc: 0.9992 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00109: val_acc did not improve from 1.00000\n",
      "Epoch 110/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 1.1798e-04 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00110: val_acc did not improve from 1.00000\n",
      "Epoch 111/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 3.5841e-04 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00111: val_acc did not improve from 1.00000\n",
      "Epoch 112/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 1.9165e-04 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00112: val_acc did not improve from 1.00000\n",
      "Epoch 113/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 8.8818e-04 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00113: val_acc did not improve from 1.00000\n",
      "Epoch 114/200\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 9.7342e-04 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00114: val_acc did not improve from 1.00000\n",
      "Epoch 115/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 7.4974e-04 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00115: val_acc did not improve from 1.00000\n",
      "Epoch 116/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.0023 - acc: 0.9982 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00116: val_acc did not improve from 1.00000\n",
      "Epoch 117/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00117: val_acc did not improve from 1.00000\n",
      "Epoch 118/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.0028 - acc: 0.9984 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00118: val_acc did not improve from 1.00000\n",
      "Epoch 119/200\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.0054 - acc: 0.9980 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00119: val_acc did not improve from 1.00000\n",
      "Epoch 120/200\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 1.2825e-04 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00120: val_acc did not improve from 1.00000\n",
      "Epoch 121/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00121: val_acc did not improve from 1.00000\n",
      "Epoch 122/200\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.0029 - acc: 0.9996 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00122: val_acc did not improve from 1.00000\n",
      "Epoch 123/200\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.0113 - acc: 0.9974 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00123: val_acc did not improve from 1.00000\n",
      "Epoch 124/200\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 4.2704e-04 - acc: 0.9999 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00124: val_acc did not improve from 1.00000\n",
      "Epoch 125/200\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00125: val_acc did not improve from 1.00000\n",
      "Epoch 126/200\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.0089 - acc: 0.9980 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00126: val_acc did not improve from 1.00000\n",
      "Epoch 127/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 9.0336e-04 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00127: val_acc did not improve from 1.00000\n",
      "Epoch 128/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00128: val_acc did not improve from 1.00000\n",
      "Epoch 129/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 4.1272e-04 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00129: val_acc did not improve from 1.00000\n",
      "Epoch 130/200\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00130: val_acc did not improve from 1.00000\n",
      "Epoch 131/200\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 2.0510e-05 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00131: val_acc did not improve from 1.00000\n",
      "Epoch 132/200\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.0097 - acc: 0.9983 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00132: val_acc did not improve from 1.00000\n",
      "Epoch 133/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0023 - acc: 0.9984 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00133: val_acc did not improve from 1.00000\n",
      "Epoch 134/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.0199 - acc: 0.9982 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00134: val_acc did not improve from 1.00000\n",
      "Epoch 135/200\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 2.3135e-04 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00135: val_acc did not improve from 1.00000\n",
      "Epoch 136/200\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 4.9331e-04 - acc: 0.9997 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00136: val_acc did not improve from 1.00000\n",
      "Epoch 137/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 3.8644e-04 - acc: 0.9999 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00137: val_acc did not improve from 1.00000\n",
      "Epoch 138/200\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 1.1418e-04 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00138: val_acc did not improve from 1.00000\n",
      "Epoch 139/200\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 1.3600e-04 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00139: val_acc did not improve from 1.00000\n",
      "Epoch 140/200\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 1.1436e-04 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00140: val_acc did not improve from 1.00000\n",
      "Epoch 141/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00141: val_acc did not improve from 1.00000\n",
      "Epoch 142/200\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.0015 - acc: 0.9987 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00142: val_acc did not improve from 1.00000\n",
      "Epoch 143/200\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 6.7948e-04 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00143: val_acc did not improve from 1.00000\n",
      "Epoch 144/200\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00144: val_acc did not improve from 1.00000\n",
      "Epoch 145/200\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 7.3993e-04 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00145: val_acc did not improve from 1.00000\n",
      "Epoch 146/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00146: val_acc did not improve from 1.00000\n",
      "Epoch 147/200\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.0041 - acc: 0.9979 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00147: val_acc did not improve from 1.00000\n",
      "Epoch 148/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 6.5675e-04 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00148: val_acc did not improve from 1.00000\n",
      "Epoch 149/200\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 4.1472e-04 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00149: val_acc did not improve from 1.00000\n",
      "Epoch 150/200\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.0050 - acc: 0.9982 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00150: val_acc did not improve from 1.00000\n",
      "Epoch 151/200\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.0043 - acc: 0.9989 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00151: val_acc did not improve from 1.00000\n",
      "Epoch 152/200\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.0019 - acc: 0.9988 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00152: val_acc did not improve from 1.00000\n",
      "Epoch 153/200\n",
      "30/30 [==============================] - 0s 17ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00153: val_acc did not improve from 1.00000\n",
      "Epoch 154/200\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 3.2667e-04 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00154: val_acc did not improve from 1.00000\n",
      "Epoch 155/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 2.7626e-05 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00155: val_acc did not improve from 1.00000\n",
      "Epoch 156/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 1.9053e-05 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00156: val_acc did not improve from 1.00000\n",
      "Epoch 157/200\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 7.8001e-04 - acc: 0.9997 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00157: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 00157: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 158/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 9.8627e-04 - acc: 0.9995 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00158: val_acc did not improve from 1.00000\n",
      "Epoch 159/200\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.0041 - acc: 0.9989 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00159: val_acc did not improve from 1.00000\n",
      "Epoch 160/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0042 - acc: 0.9980 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00160: val_acc did not improve from 1.00000\n",
      "Epoch 161/200\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.0021 - acc: 0.9996 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00161: val_acc did not improve from 1.00000\n",
      "Epoch 162/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.0324 - acc: 0.9986 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00162: val_acc did not improve from 1.00000\n",
      "Epoch 163/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0234 - acc: 0.9986 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00163: val_acc did not improve from 1.00000\n",
      "Epoch 164/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00164: val_acc did not improve from 1.00000\n",
      "Epoch 165/200\n",
      "30/30 [==============================] - 0s 17ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00165: val_acc did not improve from 1.00000\n",
      "Epoch 166/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0097 - acc: 0.9992 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00166: val_acc did not improve from 1.00000\n",
      "Epoch 167/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.0190 - acc: 0.9989 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00167: val_acc did not improve from 1.00000\n",
      "Epoch 168/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0033 - acc: 0.9991 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00168: val_acc did not improve from 1.00000\n",
      "Epoch 169/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.0027 - acc: 0.9980 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00169: val_acc did not improve from 1.00000\n",
      "Epoch 170/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0019 - acc: 0.9999 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00170: val_acc did not improve from 1.00000\n",
      "Epoch 171/200\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 7.1605e-04 - acc: 0.9996 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00171: val_acc did not improve from 1.00000\n",
      "Epoch 172/200\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 4.7655e-04 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00172: val_acc did not improve from 1.00000\n",
      "Epoch 173/200\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.0163 - acc: 0.9988 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00173: val_acc did not improve from 1.00000\n",
      "Epoch 174/200\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 3.0928e-04 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00174: val_acc did not improve from 1.00000\n",
      "Epoch 175/200\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.0020 - acc: 0.9991 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00175: val_acc did not improve from 1.00000\n",
      "Epoch 176/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 6.1552e-04 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00176: val_acc did not improve from 1.00000\n",
      "Epoch 177/200\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.0019 - acc: 0.9982 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00177: val_acc did not improve from 1.00000\n",
      "Epoch 178/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 1.1565e-04 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00178: val_acc did not improve from 1.00000\n",
      "Epoch 179/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 5.4725e-04 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00179: val_acc did not improve from 1.00000\n",
      "Epoch 180/200\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 1.9072e-04 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00180: val_acc did not improve from 1.00000\n",
      "Epoch 181/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 1.5136e-05 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00181: val_acc did not improve from 1.00000\n",
      "Epoch 182/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 1.2215e-04 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00182: val_acc did not improve from 1.00000\n",
      "Epoch 183/200\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 4.8931e-04 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00183: val_acc did not improve from 1.00000\n",
      "Epoch 184/200\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.0020 - acc: 0.9991 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00184: val_acc did not improve from 1.00000\n",
      "Epoch 185/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00185: val_acc did not improve from 1.00000\n",
      "Epoch 186/200\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00186: val_acc did not improve from 1.00000\n",
      "Epoch 187/200\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 7.6856e-04 - acc: 0.9994 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00187: val_acc did not improve from 1.00000\n",
      "Epoch 188/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 6.5826e-05 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00188: val_acc did not improve from 1.00000\n",
      "Epoch 189/200\n",
      "30/30 [==============================] - 0s 17ms/step - loss: 6.2839e-04 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00189: val_acc did not improve from 1.00000\n",
      "Epoch 190/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0022 - acc: 0.9991 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00190: val_acc did not improve from 1.00000\n",
      "Epoch 191/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0037 - acc: 0.9993 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00191: val_acc did not improve from 1.00000\n",
      "Epoch 192/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 1.5446e-04 - acc: 1.0000 - val_loss: 1.0316e-08 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00192: val_acc did not improve from 1.00000\n",
      "Epoch 193/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0038 - acc: 0.9986 - val_loss: 1.9486e-08 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00193: val_acc did not improve from 1.00000\n",
      "Epoch 194/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 3.0850e-04 - acc: 0.9999 - val_loss: 1.8340e-08 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00194: val_acc did not improve from 1.00000\n",
      "Epoch 195/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 5.4427e-04 - acc: 1.0000 - val_loss: 8.0237e-09 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00195: val_acc did not improve from 1.00000\n",
      "Epoch 196/200\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.0229 - acc: 0.9980 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00196: val_acc did not improve from 1.00000\n",
      "Epoch 197/200\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 4.5087e-04 - acc: 0.9997 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00197: val_acc did not improve from 1.00000\n",
      "Epoch 198/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00198: val_acc did not improve from 1.00000\n",
      "Epoch 199/200\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00199: val_acc did not improve from 1.00000\n",
      "Epoch 200/200\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 6.6738e-04 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00200: val_acc did not improve from 1.00000\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    validation_data=(x_val, y_val),\n",
    "    epochs=200,\n",
    "    callbacks=[\n",
    "        ModelCheckpoint('models/multi_hand_gesture_classifier.h5', monitor='val_acc', verbose=1, save_best_only=True, mode='auto'),\n",
    "        ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=50, verbose=1, mode='auto')\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA9EAAAJNCAYAAAA24/b/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAABqYElEQVR4nO3deZxbdb3/8fcnyWydTlfaUttSWihLgVJqKVcQAQFlURDcEPXiWkEQFa9XQVHUn1e5iriDKFxBAUXcEFGgoCKbUAptKaVSWkpbSvd9tiyf3x/fpMlMZ6aZmZPJTPp6Ph7pNCfnnHxzTrZ3Pt/zPebuAgAAAAAAexYrdwMAAAAAABgoCNEAAAAAABSJEA0AAAAAQJEI0QAAAAAAFIkQDQAAAABAkQjRAAAAAAAUKVHuBhQjFot5XV1duZsBAAAAACiBxsZGd/cBUeQdECG6rq5OO3fuLHczAAAAAAAlYGZN5W5DsQZE0gcAAAAAoD8gRAMAAAAAUCRCNAAAAAAARRoQx0R3pKmpScuWLVM6nS53UwYcM1M8HlddXZ3Gjx+vqqqqcjcJAAAAAAaEARuily1bpn322UejRo1SLEZBvVjuro0bN2r79u1qaGjQqlWrNGnSpHI3CwAAAAAGhAGbPtPpNAG6B8xMI0eOVHNz866/AAAAAIDiDOgESoDuGTNr8xcAAAAAUBxSaA9t2LBBV199dY+WPeGEE7Rhw4ai53/llVf06quv9ui+AAAAAADRIUT30MaNG/Wzn/2sw9uSyWSXy/7jH//QPvvsU4pmAQAAAABKiBDdQ5/5zGe0cuVKHXLIIbrwwgt1zz33aObMmTr55JM1ZcoUSdKpp56qww47TAceeKCuueaaXcuOGzdOa9as0ZIlSzR58mSdd955OvDAA/X6179eO3fu3O2+7rvvPp1xxhk66qijdNJJJ+mf//ynFi1apPnz5+uCCy7QEUccoalTp+raa6/VokWLdNNNN2nGjBk64ogj9B//8R9atGiRnnvuOUYyBwAAAIBeGrCjc5fbNddco7e85S16/vnnJUn33HOPFi1apKefflqHHHKIJOnWW2/V6NGjtXPnTk2fPl3ve9/7NGbMmDbrefnll3Xrrbfqda97nc444wzdcsstuuiii9rMM2vWLP35z3/W2LFj9ZWvfEV33HGHfvCDH+jjH/+4EomEFi5cqPnz52v8+PHKZDL68pe/rIceekipVEo1NTXab7/9lE6nOYYcAAAAAHqpIkL0JZds04IF0T6UadNS+uEPh3RzmWm7ArQkXX311br77rslSa+++qoWLVq0W4geN26cXve610mSjjrqKC1fvny39a5Zs0YXXXSRNm7cqB07duy6j8cff1xf//rXJUl1dXXasmWLHn/8cR1//PGaNGmS1qxZoy1btmjt2rUaPny44vF4tx4PAAAAAKAtSpMRGjRo0K7/33PPPfr73/+uuXPnasmSJTr00EM7PJ1UdXX1rv8nEokOu1xfeeWV+tCHPqRnnnlGV155ZYfrmTJlikaNGqWWlhZt3bpV7q6xY8dq4sSJymQyev7559XU1BTRIwUAAACAvVNFVKK7WzGOwrBhwzo8fjlny5YtGjp0qBoaGvTMM89o/vz5Pb6vbdu2ad9991UikdDdd9+9K2gfe+yxuvPOO3XaaaeptbVV6XRaZ555pq644gotXbpUEyZMUHNzs8aOHavGxkY1Nzerrq6ux+0AAAAAgL0dlegeGjNmjGbOnKkpU6bowgsv3O32c845R6lUSpMnT9ZnP/tZHXnkkT2+r8985jOaPXu2Xvva12rixIlqaWnRokWL9NGPflStra064ogjdOSRR+rmm2/Whg0bdM011+hd73qXZsyYoTPPPFOLFi2SmWno0KG9ecgAAAAAsNczdy93G/aovr7e21d9FyxYoGnTppWpRQPf4sWLdeihh+76CwAAAADlYmaN7l5f7nYUg0o0AAAAAABFIkQDAAAAAFAkQjQAAAAAAEUiRAMAAAAA+jUzu8nM1pnZs53cbmb2fTNbamYLzGxGqdpCiAYAAAAA9Hc/l3RaF7efLmlK9jJb0nWlagghGgAAAADQr7n7Q5I2dTHL2ZJu8eBxScPMbGwp2pIoxUr3Ju5pZTKtisWqZRbvct5BgwapsbFxt+nz5s3TjBmd9zZYvW21Njdv7nVbC63dvlbn/uhctba0qvrB6kjXDfQXqZS0fp0Ui0tjxhS/XCYtNTVLzU3hbyop1dRKdbVSbZ1UUyOZRdhQl1qTUlNTuM/mZqmqWho+XKqraztr405p82bJYtLoUVKiql3bM9KGDVJTY7bNdaHd1dWSOmhzKilt3iI1NkoNg6Whw6R4129lJZdJS+vXh+1Qm93mdXVSdZU6fAxR84y0bZu0ZauUTrW9bWbrf+m7F3xYRx+9+3JXPHCFfv/87yNqRNgv27ZJ+4yU6gd3PXsmHdq7fZuUSGS3WW3YfslU/rnc3Bz2b+65XFcbnjNNzdnnX3PYxLltXlcb1t/+9RAls/Cayt1nTY3U2ppvT0tzeJ7XFTymWEfPUZe275C2bJaS7dq4a5vUheWrqjpYvkA6XbDNmsJ7SW3BNquqkppb8vO0tIT77/lGkIY0SCNHhtd2dzQ2hveEXBtz26mq3Ud7Oh22Z67Nra3da7OZVF2TX39NTdjOTQXPLc90r+2DBkmjRu/+npNOh/fu9l+ZElXSsGFSQ0Nx78GeCe3KPb9bW6RundnVwvtO4XOnr94fW1vDc3nHTrXZT7GYNGRIad+rk61tX/O73hOyrwGztq+PTCb/3KutC+1qbs5/ppX89dOBqqq272MZz7enqXn39/Z4vO38sVjb506yte38Fss+5tr8+1ZHn0/pVHhv3rFdqq+Xhg0P70e7camltYP36oLt3n5/J5P5+Zuadn9M7VVnhmv7dx/d06Yb6MZJWllwfVV22pqo74gQHYmMIn/1ZzUlm7RmxxrVV9WrOh5d2K2KV2namGnatm2bhgwZEtl60Tn38EU3HuGrLpmUqhLqk2DRXlOT9MzT4Yv+sa8LHwxtuLT4eenFF6XXvS58Odyj7IdITSeBTwofZK3tviC3/2LjLi1bJi2Yn/8yPbFWOuigLu46I61+RVq6VFq3Nj99cIM0ZJC05VVpa0t+euEXuHhCOuSQcIl18AW4tTV8oLf/0tfUKL24TFr2YvjAzK1r2DBp61Zp27/Ddp1yoJRKh7Zt3xa+yKZSUuNy6YgjpAMPDOtes0Z66qkQtIePkLavlrZkH3+iShoxXBoxQhoxUkrEw32vXh1uH9IgrVsubYhLE/eTJh8QtmtOJi1t2SJt3CRt2hS+3KXTnW9PSRpUL43M3t+IEeEDPrf8pk3hS8eBB0gTJ2Z/DHBp1Wpp3rzwxWD4CGnbKmlz7ouBdf1Ur66Rjpkl7dvBb84rVkjzngrbbRcLX0ZzbRwyJGyP5cvCPmsYIu0zND/75poFerTmvzTrDedq1rThuvhi6d3vDo9jwdoF+ubD39TR447W/sP277B9mUx43RRKJLJfvgps2SLNnStt2hieNyuXS/vtJ00/qu0+kYcvZ0uXhseXToXnSzIprd+x+/0nqsIPMy0t0oatu98ei4fbMxlp8wppU7tAZBa+uI8YHO1bTiolbdkgbdv9N2bV1IT7bNzY9jE1DAnPqZEjwmNety681zQ1hufd6BH5NrqknVvbPaY9PJcKg1bDEGlIrbR5jbSldfd5B9VL+wyT4r3o29faIq19WWpukI6eGYKlFPbV8uXhPSKTyb+WRo6Qtm4L+37b1vAjWUODtPllaXPuddnuMbZ5TA3SqKFSrBs7Mp2WtqyW1nWwn6qrw+u1eg8/TrRZX0Za82+p6aXw3J64X5i+4uXw2dLaKo19Tdvtummd9Mqy8Do44ABpzL7h9bJpU3i9bN/e9j4KH/OgQdLIYd0LnpmMtG29tGFbflqkP6Aq+948In8xSUtflF5dE+5rzL7Zz/msnTukdSukjXFpv4nS/hOlxqbw+DdukrZuCe3uKd/1T/Y9YVjYjlu6eE9IJKTNhe/VBfri9dPRY9i+Sdq4Vbt9PY/FwnvGoEFtXx+NO6TNKwtePwWGDJWGt/vhprUlPKat2ccUj4f15j5PamvDa3fly2F/DBkqbXhJ2mjS+PHS5Mnhu0zuubtpcz4EV1WFdbV/ry68/zb7qZPH1F5dVUMXt/YbCTObW3D9Bne/oWyt6YJ5t36SK4/6+nrfuXNnm2kLFizQtGnTytQi6eKLL9aECRP0uc99VplMsz772SvV0NCgyy67TKeddpq2bt2qVCqlq666Sueff76kzivRJ554orZv367m5ma9//3v11vf+lZJ0nPPPaer/t9VSqaSGjFkhG782Y1qbGzU9773Pc2fP1/JZFIXXnihTj31VO2zzz4a041S2+LFi3XooYfu+ovS++hHpdtuk772NenSSzv5JbIb7rhDOv986fDDpUsuCf8fNCiatnYlk5FuuEH63OfCG/ywYdKOHdKtt0pnnx3maWkJj/cXvwhtqq6W/v536cgj267LXXrwQenRR6UnngiXdetCMLzkEum97w2/3LpLjzwi/fCH0m9/2y4IKWzLI4+UZs2SjjpKuuUW6eGHpRNPlK6/PrT17rulBx6QTjih7bKbNkk/+Yl03XXSypXShAnSBz8oHX+8NHNmeHy5ti5fLj35pPTcc20D5LPPSn/8o3TYYWHbHHtsuP2vfw1t/utfw+N47WtDGw87TLrnHul3vwvb84wzpHPOkY45Rjr00PBhvGOH9MtfhuUXLQr3M2uWdPHF0rveFcLeRRdJ998flps4MTwnDj00PJ7jjw/rXrIkv22feEKaX/DDwsiR0kc+Il14obT//tLChdKPfhT2WwdvVZJCqJkxIzyWoUM7nif3PMnd96pVbW87+OCwbZ97Tnr66RBeP/CBEAT/+MewL3/6U+noo8N2XLw4rGfZss7vT5L+9KewL773vfD8ybXjS1+Svv516fWvb7v/W1ulBQvCujdnO/vE49Lb3haWP+GEtl9aFqxdoOnXT9cptZ/Typ9/Q88/H7b9/fdL59/9Vv1zxT+1/JPLNbyu7S9Ka9aE58VPfhL+397EiWHfHn10qMBfe2143n33u9I73iF985vS//xPeA594QuhOv3kk6HdGzeGL2vnnx+eG7lOTRs3hiD+9NPSuHFh/VOm5H/k2b49/Fgxd24IVLnnZa5C29yc3zaZTLj9yCN37xkRpVdeCY9r0aLww9CsWWHb5PbBpk2hvbnn8r/+Fd4vct70prDfzjij46DU0pJ/TB3th0JDhoTnaOHz3D0E9SeeCM/VI48M+2zUqGge/733htf08uXhPUiSbr897Is3vEHad9+wfZYvzy8zY0Z4zOedF/ZNMhm23xNPSC+/3Hb9DQ35x5R7X+uJtWtDOxYulCZNCvtp0qSehcv586XZs0N73/SmsI577w3rvOGG3T8zMplw+w9/KP3lL/mQPGrU7s9hKbxfTZ8e9tO++/b4IWvr1vDcmzt396DeW+vW5bdn7nNl7FjpYx8L22ZsBz8KLlgQ3qt/+cv8e/WgQWHfzpghDd5Dz5U9GT8+vLcdfnh+exa+flKpsE2POir/nlD4Xr1xY2hLV6+fadPCOkaP7l1bu7JzZ3gPfPLJ8D6Ze0zVndSkCl8/27eH18uMGeG105HcD/aFn7Hz5uV/FB88WLrgAunjH5emTg2P/7rrpBtvDD/+SKEt06eH52/u0tF79ZNP5pfJec1rwvzTpnX+mAYaM2t09/o9zLO/pLvd/fAObvuJpL+7++3Z60sknejukVei5e79/jJo0CBvb/78+btN60uPPPKIz5w50zOZlKdSO3zy5Mm+dOlSb21t9U2bNrm7+yuvvOITJkzwdDrt7u51dXUdruvBBx90d/fVq1f7lClTfP369b569Wofs+8Y/8Njf/B/v/JvX7Rokbu7f/azn/VLL73Ud+zY4UuWLNl1X8lkslvtf+6559r8RWn98Y/ukvsBB4S/M2a4P/VUz9f3pz+5JxLuM2e6H3FEWOewYe6XXeb+4IPuW7e2nT+ddl+yxP32293nzevZfa5dG+732GPD/Z10kvu//+3+yivuRx/tbuZ+9dXu69a5H3dcmOerX3Vftsx9/Hj3UaPcFy/Or+/5591PPDHMZ+Y+dar7BRe4f+1r7tOnh+lDh7rPnu1+5JH5x/jpT7v/3//lLzfe6P75z7u/8Y3uDQ1hvhEjwm2ZTLivrVvdDz7YffRo95Urw7RMxv0Xv3DfZ5+wzMknu//+9+7dfCnt8qc/uU+YEB7Lu97lPnlyWO/Yse6XX+7+iU+4H3OMe3V1mD58uPt//Zf7iy92vd5Mxv2RR9znzu34tl/+Mmzb6mr3r3zFvbm56/U1Nbn/61/hOdnU1PE8mze733Zb2+18yy3hOdvSsudt0d7q1eH+7r8/rLuw/Y8+6n7++e5VVe51de7f+lbP98H27e5nnRW278UXh/3+jneE6x/5SOdtz2TcX3jB/be/dX/55a7v472/fa/X/b86X7V1td92m3s87j79rH+6rpL/z0P/02beefPc3/3u8FqV3E8/3f2GG9pu1299K8wzaVKYR3L/4AfdN2xoe7/PPed+/PHh9lgsvO4//OGwvvbz7i0yGfcVK8Lr9vnny92aaOzc6f7f/x2eV4MGuV94ofuCBW3nWbfO/Z57wus49x43kKVS7j/4gfvgweHygx+EaXuydKn7737nvnx5ZWyHnTvdH37Y/c9/dm9tLW6ZzZvD+9b8+T1/30S0Wlvdn346PDfbfxfL2bnT/Q9/cH/yyT1/Zu9tJO30PeRCSftLeraT286U9BeFovx/SHpiT+vr6aUiKtGf+s2H9cz6hZHe5/RRR+i777yxy3kmT56sBx+cozVrVuriiz+tefPmqaWlRbNnz9Zjjz2mWCyml156SS+88IImTJjQaSX6Yx/7mB5//HElk0mtWrVK9913n9atW6fr/+96ff3HX9fk+sl6ecXLGjlypM4880zdcccdmjRpkhYvXqyhQ4dq6NChGjJkiKwbPwNTiY7eP/4RjkV9+9vbTt+4Mfw6PmZM+CXxrrukT3wi/Pp8ySXSZz4TumoW64EHpDPPDNXaBx4Iv5A+/HD4Zf53vwu/EJuFiuSMGfmqQeEvmK97Xbjvd7wj/Hq5bVv4hf3JJ9tWdtxDxfOJJ6SXXgrTRoyQvvMd6T//M195aGoKlcQ77gjtSSalm28OFVNJ+ve/Q2W0qiq0+Y47pP/3/8Iv51dfHaoohUcVuIfq9I9+JP3mN+EX3Fy1vb6L3yczGemFF8K2bl9pWbw4/GI7dar0859Ln/xkvop7/fXhl+De2rFDuvJK6Qc/CNXoSy4JFebCykhra6jQHnBAdD0Htm4N9z1uXDTrK4cNG8Lzqahu/11Ip6XPf1769rfDc3HHDulb35IuuyyabpjLNi/TwT88WB856iO67i3X6bbbXO+d8wbVjF2qNZcv1fDB9dqxI1S/v/e98Lz+0IdChfHAA7te9/r14bV4wAEd357JhOfxxIm9rzShf3v11VDh66q3R6VZvz78jaqyD2Dg2VMl2sxul3SipH0krZX0ZUlVkuTu11sIQz9UGMG7UdIH3X1ux2vrHY6J7oWzzjpLt956m9aseUVvf/s5kqQbbrhBGzZs0MKFC1VTU6Nx48Z1GJxz/v73v+tf//qXHnvsMW3cuFHnnXeempub1ZhsVMYyGpEYoaFDhurggw/W1q1b1draqk2bNmnKlCmaOnWqtm3bpvXr12vz5s3af//9++iRD1xbt4ZjRp94InRL2m+/0J1o1qzQfan9l+yWltDd7MknQ8g87bRwDGR7L70kveUt4Qv7pz4VvsDnuhNefHHohnjvvSGwvuMd0imnSJdfHoLvD38onXVWmO/kk7v+ov/oo6HL9JQpoYtwLngef3y4bNqU7+b5xBOhq/To0SHMzpoVguI//yn9+Mehq/SnPx1Cy/PP57vF1de3bcPIkfluxLNmhe5N7cNfXV3odjh1qvTrX4eQOmtW/vaDDgqB9cQTQ7h3D8H52ms77mJnJh13XLj8/OcdH0/ckVgsdBXuyKGHhm7e554b2tnQELb9hRdGNzjL4MHhMV1zTcfHRkvhOXDEEdHcX87QoQP/y/Y++0Sznng8hOZDDpG+8Y3Q3fGss6JZtyRNHj5ZH3vtx3T93Ot12esu07CjX5BeeFgtd/9YH11SrwsuCD+evPxyeG594xvFd50dNarrABGLhR/kUPl60/V4oCI8A9gTd3/PHm53SRf3VWP6/aU/dud2d587d65Pnz7dJ07cz5cvD30yv/a1r/kFF1zg7u5/+tOfXJI/n+1n1lF37j/84Q9+/PHHu7v7448/7tXV1f7Agw/4Q4se8jFjx/ji5xd7c3Ozb8j217vkkkv8Qx/6kLe2tnoqlfJNmzZ5Y2OjP/vss91q+97WnXv1avfXvjbfXVIKXW+rqvLXx4xxP/TQ/OXgg9veXlsbrj/6aNt1p9Oha3NDQ+heKbmfeWboxvOrX4XrX/96x+1asSJ09c11KT7qqM67/7z0UujePGWK+5o1vdse6bT7X//qfu657m95S+h2/de/lr5b6BNPuL/5zaG7Wrlcc437+9+f79YNdNea7Wt80NcH+bt+8y6fdt00P+B7B/i3v9O6671i6tTQLRMAABRPRXTn7i+XiujOXU4HHXSQhg8fpscee1SxWEJr1qzR6aefrsbGRk2bNk3z5s3TX/7yFx188MEdduduaWnRG9/4Rm3atEkHH3yw1q5dq498/CM68uQjteihRfru1d9VMplUQ0ODbrzxRjU1Nenaa6/VvHnzlE6nddFFF+nUU0/V+PHjNbQbpai9rTv3+eeHrs5f+ELovjtzZuiWnKs0P/FEqFC3e5rtGjRl1qxQZZw5M3RdnjcvXyn4wQ/CQGE//WkYpOn660Ml6tBDw0A5Bx4YBsXqaiCx5uZQcb3ootAF9NJLd5/n058OldMlS8KojgDK54sPflFf/+fXJUm3nXub3nPEe3TDDaE79qWXVs4gLwAA9JViBhbrLwjRveSeUSbTJLMaxWK97x2f8YwWrVukmMU0ddTUbh3n3B39LURv2xa6Qr/mNdGv+x//CN2Iv/Ql6Stf6d26FiwIxxPPmBGO7X3ppdBF+sQTpT//Od/leM4c6Z3vDOH46adD19JiHHtsOC5syZK23YG3bw/dzc88M4zwDaC8tjZv1eTvT9aEIRM072PzFOvuyX0BAEAbAylE86kfmWh+jNjQuEEt6RaNGzKuZAG6v3EPx/keeGA4fVFPNDWF09u0P/VRKhWqwhMnhtMc9da0aeHUBA8/HCrDH/hAOG3Cz37W9pjdU04JFe5HHy0+QEthsKulS8OpOwrdfHP4oeGTn+z9YwDQe0Nrh+rhDz6su8+/mwANAMBehk/+fiSdSWvN9jUaXD1YQ2sG+ChB3XDvveEcwkOHhkG3vv71/CBXxXAPI0WfdVa4bC04Mf2PfxzOG3vttdGNhHzeeWGk3x//WHrssdDFuqMK+n77hXModse554YRlr/3vfy0TEb6/vdDl/Jjjuld2wFE59BRh2r8kPHlbgYAAOhjjM7dj6zbuU7JTFKTGybvNVXoTEa64opw7PEzz4Rjgr/4xTBa9E9/Kq1Zkx9tOpORrrqq7amQpDAS7513hmr2n/8cRnT+059CaL7ySunNb5be9rZo23311dKKFWHk6vd0OU5g91RVSR//eDh2+7nnwijS994bTtt0663R3Q8AAACAnilZiDazCZJukTRGoa/zDe7+PTO7StJHJWXPCKgr3P2entxHJpNRrLPzyAwwqUxKr+54VUNrhqqhpqGk95U7Dr4/HA//m9+EY4Z/8YsQjn/5yzAg15VXhmDc3Bzmq6kJXbPvvz8E5NzZvObMCaeKeuc7w6mV/va3cJ7mWbNCFbipKVR1o/5NIpEI7SuFj35U+upXw4Bl110X2j92bKjSAwAAACivUibQlKTPuPtUSf8h6WIzm5q97Vp3n5699ChAx+NxrV+/XplMJqr2ltWrO15V2tMaN2RcSe/H3bVx40bV1tbu+ttbO3eG6u8NN3RvuWQyhOXDD89Xc81CJfoPfwhdtH/843B+5m3bwnmRV60KAfnRR8OgXuedF0L3TTeFZd/4Rulf/5KGDw+B+7LLOj9vcH81alQ4h/Mtt4Tu4vfeGyr0jPYLAAAAlF+fjc5tZn+U9ENJx0na4e7fLnbZjkbnbmpq0rJly5ROp6NtaLe53NOSYrIeDi6T9rTWNa1TbbxWw2uGR9u8DpiZ4vG46urqNH78eFVVVfVqfV/8YjiOeeTI0MW5vsgx9X76U2n2bOmPfwzHMhdjyRLpLW+RXn45HHO8bl0I2VOmtJ1v0ybp9tulD34wumOh+9L8+WHU79GjpS1bpJUrw/8BAACASjSQRufukxBtZvtLekjS4ZIuk/QBSdskzVWoVm/uavmOQnR/0dq6QY8+OkoHHvh9jR//iR6t46K7L9LPnv6ZllyyRJOHD6wTAC9dKh12mHTkkeHY5e9+t7gRpJuaQvDdb79wDuXudLfeuDF02X7ooRDA3/rWHje/XzvxxHB6rgsuCOeQBgAAACrVQArRJR9YzMwGS/qtpE+5+zYzu07S1xSOk/6apGskfaiD5WZLmi1J1f24H6tZXJKy1ejuy3hGv1z4S71v2vv6bYDOZEJ36VNPDaeKKvSpT4Vuxn/8Y+iS/a1vddz1+J57wgjcOUuXSqtXh8Gyunu88siR4VjolSvDgGSV6nOfkx5/PJxKCwAAAED/UNIQbWZVCgH6Vnf/nSS5+9qC238q6e6OlnX3GyTdIIVKdCnb2Rv5Ltw9Ozb7pS0vaUfrDh034bjoGhWxv/0tDHY1alQ4VvnYY8P0u+8Oo2F/+9th4KsrrggjYf/iF9KHP5xf/sEHQ7U4kZDi8fz0886TTjihZ21KJCo7QEvS6aeHrtwRHLYOAAAAICIlG1jMwjmabpS02N2/UzB9bMFs50h6tlRt6Bu9q0QvXLtQknTE6CMia1HUfv3rcJzz0KHSSSeF6nFzc+i2feih0qWXhvlOPVWaMSOc/il3qPrLL0vvfrd0yCHShg1SY2P+cvvt5XtMAwUBGgAAAOhfSjk693GS3i/pjWb2TPZyhqT/NbOFZrZA0kmSBnRn1Vx37p5WoheuCyH6sNGHRdSiaCWT0m9/G87B/PjjoQr9vveF43WXLQunYcqNS2YWqtEvvBCWaWqSzj1Xam2Vfv97qaG0Z+4CAAAAgJIrWXdud39YUkdHu/bolFb9Va47d08r0QvWLtABww/Q4OrBUTYrMg88EEa6fve7w7HI994rXXyx9LOfhXMzn3xy2/nPOSdUnf/nf6S//EV66qlwvPRBB5Wn/QAAAAAQpZIPLFb5ct25e16JPmJM/+7KPXRoONZZCgOG3XBDCNWzZu0+fywmff7z0gc+EE7T9KUvFX/6KgAAAADo70rZnXuvkB9YrPuV6OZUs17Y+EK/PR66pSV0w37b26Samvx0M+mUU6QhQzpe7vzzpalTw3Jf/nJftBQAAAAA+gaV6F7Kd+fufiV68frFSnu634bo++6Ttm4NVefuqKqSnnkmjKDd3dNXAQAAAEB/RoiORKxHx0QvWLtAkjRtzLSoGxSJX/9aGjEiVJ27KzfYGAAAAABUErpzRyCM0N39EL1w3ULVJmp14IgDo29ULzU1hQHBzj2XQAwAAAAAOYToSMR61J174bqFmjpqquKx+J5n7mN/+Yu0Y4f0rneVuyUAAAAA0H8QoiNgFu9Rd+6Faxf22+Ohf/1radQo6aSTyt0SAAAAAOg/CNERCN25u1eJ3tC4QWt2rOmXx0Pv3Cndfbf09reHwcEAAAAAAAEhOhLdH1hs4dqFktQvK9E33yw1NkrvfW+5WwIAAAAA/QshOgI9qUQvXJcN0WP6V4hOJqX//V/pda+Tjjuu3K0BAAAAgP6FzroRMOt+JXrB2gXaZ9A+GlM/pkSt6plf/UpasUL6wQ84xzMAAAAAtEclOhLxbo/OvXDdQk0bM03Wj5JqJiN94xvSEUdIZ55Z7tYAAAAAQP9DiI6AWUzdOU90xjNatG5Rvzse+o9/lBYvli6/XIrxzAAAAACA3RCVIhBOcVV8JXr55uXamdxZthC9aVPorr1lS36ae6hCT54svfOdZWkWAAAAAPR7hOhIdO+Y6AVrF0gq36Bil14aLoceKv3mNyFAP/CA9OST0uc+x2mtAAAAAKAzxKUIhNG5iw/RC9ctlMl02KjDSteoTjz0kHTrrdJ//qf07LPSu94Vjn/euFEaO1a64II+bxIAAAAADBiE6Ah0tzv3wnULdcCIA1RfXV/CVu0ulZI+8Qlpv/2k666TqqtDt+4vfjGcF/rb35Zqavq0SQAAAAAwoBCiI9H97tzlOB76+uulBQukO++UBg0K0z79aencc6Xf/la66KI+bxIAAAAADCgcEx2B0J27uEr0luYtWrppqabvO72kbWpv3bpQcT711BCaC02cKF12mVRX16dNAgAAAIABhxAdieIr0X9/6e/KeEYn7X9SidvU1uWXSzt3St//vtSPTk0NAAAAAAMKIToC3alEz1k2R/VV9Tpm/DGlbVSBBx6QbropdN0+5JA+u1sAAAAAqDiE6AiYFV+JnrNsjk7Y/wRVx6tL3KrgllukM86QDj5YuvLKPrlLAAAAAKhYhOhIFDc698qtK7Vk4xKdMumUXt3b1VdLJ5wgPfVU5/NkMtIVV4RTVr3+9dJjj0kNDb26WwAAAADY6xGiI2AWUzHniX5g+QOSpFMm9y5E3357ON/zrFlhQLAdO9re/uqr0jvfKX3jG9Ls2dJf/yoNH96ruwQAAAAAiFNcRSKcJ3rPIXrOsjkaXT9ah48+vMf3lUxKzz0nfexjYYCwa68Np6f60IekZ5+VnnhCevnlcNt3viN96lMMJAYAAAAAUaESHYk9d+d2d81ZNkenTD5F1otU+/zzIUi/4Q3SdddJDz8sDR4sXXWVNG+edOyx0jXXSE8/HQYSI0ADAAAAQHSoREegmO7ci9Yv0tqda3t9PPT8+eHvtGnh73HHSQsWhC7dQ4f2atUAAAAAgD2gEh2B0J2760r0nGVzJEknTz65V/c1f75UXR1G286JxwnQAAAAANAXCNGR2PMprh5Y/oAOGnmQ9hu6X6/uaf586bDDpKqqXq0GAAAAANADhOgImMUldV6JTqaT+vtLf9fJk3pXhZZC1+0jj+z1agAAAAAAPUCIjkTXlegnVj+hHa07en1qq7Vrw4UQDQAAAADlQYiOwJ4q0XOWzZHJdNL+J/XqfnKDihGiAQAAAKA8CNERMOu6Ej1n+RzNfM1MDa8b3qv7aT8yNwAAAACgbxGiIxHvNERvb9mux1c93uuu3FII0ePGSSNH9npVAAAAAIAeIERHIJwnuuPu3A+teEipTCqSEM2gYgAAAABQXoToCITzRHdciZ6zbI5qE7U6dsKxvbqPlhZp8WJCNAAAAACUEyE6EnG5d1yJnrN8jo7f73jVJmp7dQ+LF0upFCEaAAAAAMqJEB2B0J1790r0qzte1bPrno3seGiJQcUAAAAAoJwI0REI3bl3r0Q/uPxBSYrseOjaWmnKlF6vCgAAAADQQ4ToSHR8iqs5y+ZoRN0ITd93eq/vYf586fDDpUSi16sCAAAAAPQQIToCZnG1H53b3TVn2RydPOlkxax3m9k9hGiOhwYAAACA8iJER2L3SvQLm17Qym0rdfKkk3u99jVrpA0bCNEAAAAAUG6E6Ah0dIqrOcvmSIrmeGgGFQMAAACA/oEQHYEwOnfb7txzls3R/sP21+Thk3u9/gULwl9CNAAAAACUFyE6Em0r0elMWg8uf1CnTDpFZtbrtc+bJ+23nzR8eK9XBQAAAADoBUJ0BNoPLPbUmqe0tWVrJF2577tPuvNO6Ywzer0qAAAAAEAvEaIjYNZ2YLHc8dBvnPTGXq13+XLpvPPCqa2+/e1erQoAAAAAEAFCdCTics9Xoucsm6Pp+07XqPpRPV5jY6N0zjnh9Fa/+51UXx9FOwEAAAAAvUGIjkAYWCxUopuSTXpk5SM6ZVLPu3K7S7NnhwHFbrtNOuCAiBoKAAAAAOiVRLkbUAnCKa5CJXrF1hVqTbfqqLFH9Xh9P/yhdOut0te+Jp1+elStBAAAAAD0FpXoSOSPiW5KNkmSBlUN6vHavv996Q1vkK64IpLGAQAAAAAiQoiOQBidO4To5lSzJKkuUdejdblLK1dKxxwjxdg7AAAAANCvENMiETaju6spFSrRtYnaHq1p/XqppUWaMCGyxgEAAAAAIkKIjkCoREvu6XwluqpnleiVK8NfQjQAAAAA9D+E6AjkQrSU2XVMdE8r0YRoAAAAAOi/CNGRyHXnTvf6mGhCNAAAAAD0X4ToCLSpRPfymOiVK6WaGmnUqIgaBwAAAAADnJmdZmZLzGypmX2+g9snmtkDZrbAzP5uZuNL1RZCdATMOqhE9+KY6PHjJbPImgcAAAAAA5aFquWPJJ0uaaqk95jZ1HazfVvSLe4+TdJXJX2jVO0hREciN7BYNMdE05UbAAAAAHaZJWmpuy9z91ZJv5J0drt5pkp6MPv/v3Vwe2QI0RHIVaKlfCWaEA0AAAAAkRgnaWXB9VXZaYXmSzo3+/9zJDWY2chSNIYQHYHCU1w1pZqUiCWUiCW6vZ50Wlq9mhANAAAAYK+TMLO5BZfZ3Vz+vySdYGZPSzpB0mpJ6chbKan7SQ8dyB0TnVFzqrnHVehXXw1BmhANAAAAYC+TcveZndy2WlJhShqfnbaLu7+ibCXazAZLeru7bylBO6lERyE/OndaTckmTm8FAAAAANF5UtIUM5tkZtWSzpN0V+EMZraP5Y+zvVzSTaVqDCE6Avnu3Bk1p3teiSZEAwAAAEBb7p6SdImkeyUtlnSHuy8ys6+a2VnZ2U6UtMTM/i1pjKSvl6o9dOeORP4UV03Jpl6d3koiRAMAAABAIXe/R9I97aZ9qeD/d0q6sy/aQiU6Avnu3L07JnrlSqm+Xho2LLKmAQAAAAAiRIiOREElOtW7Y6InTJDMomwbAAAAACAqhOgIRFmJpis3AAAAAPRfhOgI5AaBc0+rOdXcq2OiCdEAAAAA0H8RoiORH527KdnUo0p0a2s4TzQhGgAAAAD6L0J0BPKnI8tWontwTPQrr0juhGgAAAAA6M8I0RHInyc6DCzWk0o0p7cCAAAAgP6PEB2JfHfunlaiCdEAAAAA0P8RoiNQ2J27p8dEE6IBAAAAoP8jREcg35070+PRuVeulIYNkwYPjrhxAAAAAIDIEKIjETZja6pFaU/3uBJNFRoAAAAA+jdCdARylejmdLMk9fiYaEI0AAAAAPRvhOhIhM3YlGyUJCrRAAAAAFChCNERyFWiW3KV6G4eE93UJG3YQIgGAAAAgP6OEB2B3OjcjckmSd2vRK9aFf4SogEAAACgfyNERyJ7THSqZ8dEc3orAAAAABgYCNERyFWicyG6u5VoQjQAAAAADAyE6AjsGp071bNjonMhevz4SJsFAAAAAIgYIToSIUQ3JXteiR41Sqrt/qDeAAAAAIA+RIiOwK7u3OkWSd0/JnrVKrpyAwAAAMBAQIiOQK47d1MyhOieVKIJ0QAAAADQ/xGiI5GrRHe/O/eLL0qLF0tTp5akYQAAAACACJUsRJvZBDP7m5k9Z2aLzOyT2ekjzOx+M3sh+3d4qdrQV/IDi2W7c3djYLEvf1mqqpI+8YmSNA0AAAAAEKFSVqJTkj7j7lMl/Yeki81sqqTPS3rA3adIeiB7fYALm7El1Sqp+Er0ggXSbbdJn/ykNHZsyRoHAAAAAIhIyUK0u69x93nZ/2+XtFjSOElnS7o5O9vNkt5Wqjb0lV3HROdOcVXkwGJf+II0dKj03/9dsqYBAAAAACLUJ8dEm9n+ko6S9C9JY9x9TfamVyWN6Ys2lFJudO6WdKtiFlMiltjjMo88It19dwjQwwd8h3YAAAAA2DuUPESb2WBJv5X0KXffVnibu7sk72S52WY218zmplKpUjezl3KV6FbVJepkZl3O7S5dcYU0Zox06aV90T4AAAAAQBRKGqLNrEohQN/q7r/LTl5rZmOzt4+VtK6jZd39Bnef6e4zE4k9V3bLKdeduyXdWtTx0PfeKz30kPSlL0n19aVuHQAAAAAgKqUcndsk3Shpsbt/p+CmuyRdkP3/BZL+WKo29JVcd+7mVEtRI3N/8YvSpEnSRz5S6pYBAAAAAKJUykr0cZLeL+mNZvZM9nKGpG9KOtXMXpB0Svb6AJc7xVVyj5Xo7dulp54KAbq6ui/aBgAAAACISsn6Sbv7w5I6Ozj45FLdbznsqkSnW/c4MvfKleHv5MmlbhUAAAAAIGp9Mjp3pdt1THQRlegVK8Lf/fYrdasAAAAAAFEjREeioBK9h2OiX345/CVEAwAAAMDAQ4iOQH507uIq0YmENHZsX7QMAAAAABAlQnQkcqNzp/Z4TPTLL0vjx0vxeF+0CwAAAAAQJUJ0BHKV6OYizhO9YoU0cWJftAoAAAAAEDVCdATy3blTRR0TzfHQAAAAADAwEaIjEc7k1ZJOqjbeeSU6lZJWr6YSDQAAAAADFSE6AmYmKbbHSvQrr0jpNJVoAAAAABioCNERMYupOZXq8phoTm8FAAAAAAMbIToiqUxMKc90OTr3ihXhL925AQAAAGBgIkRHJOlhUxZTiZ4woS9aBAAAAACIGiE6IkkPI3R3dUz0ihXSPvtI9fV91SoAAAAAQJQI0RFpyYQRuvdUieZ4aAAAAAAYuAjREcl15+7qmGhCNAAAAAAMbIToiLRmuj4m2j1052ZQMQAAAAAYuAjREWnNdufu7JjoLVukHTuoRAMAAADAQEaIjkjrHo6J5vRWAAAAADDwEaIjsqcQnTu9FZVoAAAAABi4CNERafFsd+5OBhajEg0AAAAAAx8hOiLJTPjbVSW6pkYaNaoPGwUAAAAAiBQhOiItexhYLHd6K7O+bBUAAAAAIEqE6Ii07qESzemtAAAAAGDgI0RHZNcprjo5JjpXiQYAAAAADFyE6Ih0VYluaZHWrKESDQAAAAADHSE6Ii0Zl0mqjlfvdtuqVeEvlWgAAAAAGNgI0RFpzUg18bisg5HDOL0VAAAAAFQGQnREWtJSTazjzfnyy+EvlWgAAAAAGNgI0RFpzbiq412H6PHj+7BBAAAAAIDIEaIj0pJ21XYSoleskMaOlWpq+rhRAAAAAIBIEaIj0ppxVXfRnZuu3AAAAAAw8BGiI9KScdV0UYlmUDEAAAAAGPgI0RFpybiqY7uPzO1OJRoAAAAAKgUhOiIt6UyHx0Rv2SK1tEiveU3ftwkAAAAAEC1CdERaM5kOK9GNjeHv4MF93CAAAAAAQOQI0RFpTbtqugjRdXV93CAAAAAAQOQI0RFpyWRUHe88RA8a1McNAgAAAABEjhAdkZZ0psNKdFNT+EuIBgAAAICBjxAdkZZ0WtUdbE26cwMAAABA5SBER6QlQyUaAAAAACodIToC6UxayUyGSjQAAAAAVDhCdARa0i2SpOqY73YbA4sBAAAAQO+Y2WlmtsTMlprZ5zu4fT8z+5uZPW1mC8zsjFK1hRAdgaZk6LPd0Xmi6c4NAAAAAD1nZnFJP5J0uqSpkt5jZlPbzfZFSXe4+1GSzpP041K1hxAdgeZUsySppotKNN25AQAAAKBHZkla6u7L3L1V0q8knd1uHpc0JPv/oZJeKVVjEqVa8d6kKZWtRMc7uI1KNAAAAAD0xjhJKwuur5J0TLt5rpJ0n5l9QlK9pFNK1Rgq0RHIVaKrreNKdDwuVVX1dasAAAAAYMBImNncgsvsbi7/Hkk/d/fxks6Q9AszK0nepRIdgfwx0buH6KYmqtAAAAAAsAcpd5/ZyW2rJU0ouD4+O63QhyWdJknu/piZ1UraR9K6qBtKJToCuyrRnRwTzfHQAAAAANBjT0qaYmaTzKxaYeCwu9rN87KkkyXJzA6VVCtpfSkaQ4iOwK5jojsJ0VSiAQAAAKBn3D0l6RJJ90parDAK9yIz+6qZnZWd7TOSPmpm8yXdLukD7r57QIsA3bkj0NUx0XTnBgAAAIDecfd7JN3TbtqXCv7/nKTj+qItVKIjkD8mOrPbbXTnBgAAAIDKQYiOQFfHRFOJBgAAAIDKQYiOwK5joi29221UogEAAACgchCiI7Cn0bmpRAMAAABAZSBERyB3THRVB5VounMDAAAAQOUgREcgX4lmYDEAAAAAqGSE6Ag0pZpUE09I2j1EU4kGAAAAgMpBiI5Ac6o5G6Jd7c/nTSUaAAAAACoHIToCTckm1carstfy1eh0WmppoRINAAAAAJWCEB2B5nSuEi255wcXaw6HShOiAQAAAKBCEKIj0JRsUm0iVKLd85Xoxsbwl+7cAAAAAFAZCNERCMdE57pz5yvRTeHMV1SiAQAAAKBCEKIj0JTKHxNNJRoAAAAAKhchOgKFlejCY6KpRAMAAABAZSFER6Ap2aS6RHX2GpVoAAAAAKhUhOgIdFaJzoVoKtEAAAAAUBkI0RFoTjWrtoNKNN25AQAAAKCyEKIj0JRq2hWiO6pE050bAAAAACoDIToCzalm1cZrJDGwGAAAAABUMkJ0BJqSTapJ5M4TzcBiAAAAAFCpCNG95O5qSbeoLrF7JZqBxQAAAACgshCie6k51SxJqtnVnXv3gcWoRAMAAABAZSBE91IuROdH525bia6uluLxMjQMAAAAABA5QnQvNaVCubkuUStp90o0XbkBAAAAoHIQonsp352741Nc0ZUbAAAAACoHIbqXmpLZSnRVbXZK29G5qUQDAAAAQOUgRPfS7gOLtT1PNJVoAAAAAKgchOheMjPtP2x/DalpkLR7d24q0QAAAABQOQjRvTRj7Awt/+RyvX78tOwUBhYDAAAAgEpFiI5MOI8VA4sBAAAAQOUiREfELHcyaCrRAAAAAFCpCNERMQubkko0AAAAAFQuQnRkct25OcUVAAAAAFQqQnREcpVoqe0prgjRAAAAAFA5CNERyR0T3b4STXduAAAAAKgchOjItD0mOpmUUikq0QAAAABQSQjREWk/OndTU7hGJRoAAAAAKgchOjJtK9GNjWEqlWgAAAAAqBwlC9FmdpOZrTOzZwumXWVmq83smezljFLdf1/LHxMdQjSVaAAAAACoPKWsRP9c0mkdTL/W3adnL/eU8P77VH507tCdm0o0AAAAAFSekoVod39I0qZSrb//6bgSTYgGAAAAgMpRjmOiLzGzBdnu3sPLcP8l0X5gsVwlmu7cAAAAAFA5+jpEXyfpAEnTJa2RdE1nM5rZbDOba2ZzU6lUHzWv53LduRlYDAAAAAAqV5+GaHdf6+5pd89I+qmkWV3Me4O7z3T3mYlEou8a2WO57tyc4goAAAAAKlWfhmgzG1tw9RxJz3Y270CTH1iMSjQAAAAAVKqSlXjN7HZJJ0rax8xWSfqypBPNbLokl/SSpI+V6v77Wv4UV20r0YRoAAAAAKgcJQvR7v6eDibfWKr7K7+Oj4mmOzcAAAAAVI5yjM5dkfKjc3OKKwAAAACoVIToyOQq0W1PcVVbW672AAAAAACiRoiOSP6Y6Hx37ro6yaycrQIAAAAARIkQHZF8d+78wGIcDw0AAAAAlYUQHZndBxbjeGgAAAAAqCyE6Ih0VIkmRAMAAABAZSFER8Rs90o03bkBAAAAoLIQoiOTG1gsPzo3lWgAAAAAqCyE6IjkKtGF54mmEg0AAAAAlYUQHZGOTnFFJRoAAAAAKgshOjK5Y6IZWAwAAAAAKhUhOiJmJsmU687NwGIAAAAAUHkI0REyi1OJBgAAAIAKRoiOVIxTXAEAAABABSNERygMLpaROwOLAQAAAEAlIkRHKlSiW1sld0I0AAAAAPRHZvY7MzvT8ucqLhohOkK5SnRjY7hOd24AAAAA6Jd+LOl8SS+Y2TfN7OBiFyRER8gsVKKbmsJ1KtEAAAAA0P+4+xx3f6+kGZJekjTHzB41sw+aWVVXyxKiIxWXe5pKNAAAAAD0c2Y2UtIHJH1E0tOSvqcQqu/varlEyVu2Fwnd6fPdualEAwAAAED/Y2a/l3SwpF9Iequ7r8ne9Gszm9vVsoToCIXzROe7c1OJBgAAAIB+6fvu/reObnD3mV0tSHfuSMXlTiUaAAAAAPq5qWY2LHfFzIab2ceLWZAQHaHQnZuBxQAAAACgn/uou2/JXXH3zZI+WsyChOgIhe7cnOIKAAAAAPq5uJlZ7oqF8xVXF7MgITpSsTajc1OJBgAAAIDeM7PTzGyJmS01s893cPu1ZvZM9vJvM9uyh1X+VWEQsZPN7GRJt2en7REDi0Uo/HiRYWAxAAAAAIhItkr8I0mnSlol6Ukzu8vdn8vN4+6fLpj/E5KO2sNqPyfpY5Iuyl6/X9LPimkPITpSVKIBAAAAIGKzJC1192WSZGa/knS2pOc6mf89kr7c1QrdPSPpuuylWwjREWp/iitCNAAAAAD02jhJKwuur5J0TEczmtlESZMkPdjVCs1siqRvSJoqqTY33d0n76kxRR0TbWafNLMhFtxoZvPM7E3FLLs3CaNzh4HFYjGpqqrcLQIAAACAASFhZnMLLrN7uJ7zJN3p7uk9zPd/ClXolKSTJN0i6ZfF3EGxA4t9yN23SXqTpOGS3i/pm0UuuxfJV6IHDZLyY70BAAAAALqQcveZBZcbCm5bLWlCwfXx2WkdOU9hkLA9qXP3BySZu69w96sknVlMQ4vtzp2Lg2dI+oW7LyocDhxBbmCxxkYGFQMAAACAiDwpaYqZTVIIz+dJOr/9TGZ2iELR97Ei1tlioSvxC2Z2SXa9g4tpTLGV6KfM7D6FEH2vmTVIyhS57F7DLD+wGMdDAwAAAEDvuXtK0iWS7pW0WNId2cLuV83srIJZz5P0K3f3Ilb7SUmDJF0q6bWS3ifpgmLaU2wl+sOSpkta5u6NZjZC0geLXHYvEpd7OMUVlWgAAAAAiIa73yPpnnbTvtTu+lXFrCt7yqx3u/t/SdqhbmbbYivRr5O0xN23mNn7JH1R0tbu3NHeIPQGoBINAAAAAP1VdtCx1/d0+WIr0ddJOtLMjpT0GYWTUN8i6YSe3nElCqe4yuwaWAwAAAAA0C89bWZ3SfqNpJ25ie7+uz0tWGyITrm7m9nZkn7o7jea2Yd71tZKlj8muqGh3G0BAAAAAHSiVtJGSW8smOaSIgvR283scoVTWx2fHcWMsyC3EyrRSTU2SmPGlLs1AAAAAICOuHuPx/gqNkS/W2EI8Q+5+6tmtp+kb/X0TitXjIHFAAAAAKCfM7P/U6g8t+HuH9rTskWF6GxwvlXS0Wb2FklPuPst3W5phQuVaAYWAwAAAIB+7u6C/9dKOkfSK8UsWFSINrN3KVSe/y7JJP3AzD7r7nd2r52VLfRyZ2AxAAAAAOjP3P23hdfN7HZJDxezbLHdub8g6Wh3X5e9g1GS5kgiRLeRr0TTnRsAAAAABowpkkYXM2OxITqWC9BZG1X8Oab3GmZxZTKu5mYq0QAAAADQX5nZdrU9JvpVSZ8rZtliQ/RfzexeSbdnr79b0j1Ft3AvYRZTS0vYpFSiAQAAAKB/cvcen5S4qGqyu39W0g2SpmUvN7h7USl97xJXU1O1JCrRAAAAANBfmdk5Zja04PowM3tbMcsWW4nOHXj92z3OuBcLlehw+mwq0QAAAADQb33Z3X+fu+LuW8zsy5L+sKcFuwzRHfQT33VTuB8f0s2GVjSzuJqbQyW6trbMjQEAAAAAdKajXtlFFZm7nKk3/cT3TjGlUiZJqq4uc1MAAAAAAJ2Za2bfkfSj7PWLJT1VzIKMsB0hs7hSqbBJE0V3lAcAAAAA9LFPSGqV9GtJv5LUrBCk94ioF6l8JZoQDQAAAAD9k7vvlPT5nixLJTpChZXoqqoyNwYAAAAA0CEzu9/MhhVcH549rfMeEaIjFEJ0XBKVaAAAAADox/Zx9y25K+6+WdLoYhYkREcq352bSjQAAAAA9FsZM9svd8XM9lfHZ6baDfXSCJnFlU5TiQYAAACAfu4Lkh42s38onML5eEmzi1mQqBchsxijcwMAAABAP+fufzWzmQrB+WlJf5DUVMyyRL1IMbAYAAAAAPR3ZvYRSZ+UNF7SM5L+Q9Jjkt64p2U5JjpCoRJNd24AAAAA6Oc+KeloSSvc/SRJR0naUsyChOgIhdG5GVgMAAAAAPq5ZndvliQzq3H35yUdXMyC1EsjFVMqFTYplWgAAAAA6LdWZc8T/QdJ95vZZkkrilmQqBehMDo3A4sBAAAAQH/m7udk/3uVmf1N0lBJfy1mWaJehEJ37nBMNN25AQAAAKD/c/d/dGd+jomOVIzzRAMAAABABSNERyh05w7pmUo0AAAAAFQeQnSkYkqlQnqmEg0AAAAAlYcQHaHCSjQhGgAAAAAqDyE6QmYxunMDAAAAQAUjREcqTnduAAAAAKhghOgI5SrRZq54vNytAQAAAABEjRAdoXBMdBVVaAAAAACoUIToSIWBxQjRAAAAAFCZCNERynXnrqrycjcFAAAAAFAChOgImYWBxahEAwAAAEBlIkRHiko0AAAAAFQyaqYRCpXomOJxQjQAAAAAVCJCdKRiSqeNSjQAAAAAVChCdIRCJTquRIIQDQAAAACViGOiI5QbnZsQDQAAAACViRAdqbgyGUI0AAAAAFQqQnSE8qe4IkQDAAAAQCUiREco152bgcUAAAAAoDIRoiMVKtHxeKbcDQEAAAAAlAAhOkIMLAYAAAAAlY0QHSGzeDZEU4kGAAAAgEpEiI5UjIHFAAAAAKCCEaIjRCUaAAAAACobITpSMaXTVYRoAAAAAKhQhOgI5SrRjM4NAAAAAJWJEB2h/HmiCdEAAAAAUIlKFqLN7CYzW2dmzxZMG2Fm95vZC9m/w0t1/+XBeaIBAAAAoJKVshL9c0mntZv2eUkPuPsUSQ9kr1eMXHduKtEAAAAAUJlKFqLd/SFJm9pNPlvSzdn/3yzpbaW6/3Iwi1GJBgAAAIAK1tfHRI9x9zXZ/78qaUwf33+JMbAYAAAAAFSysg0s5u4uyTu73cxmm9lcM5ubSqX6sGU9lx9YLF3upgAAAAAASqCvQ/RaMxsrSdm/6zqb0d1vcPeZ7j4zkUj0WQN7IxwTXaV4nBANAAAAAJWor0P0XZIuyP7/Akl/7OP7L7FQiU4k6M4NAAAAAJWolKe4ul3SY5IONrNVZvZhSd+UdKqZvSDplOz1imEWTnGVSFCJBgAAAIBKVLJ+0u7+nk5uOrlU91lumUxM7jEGFgMAAACAClW2gcUqUTodlyQlEgNjIDQAAAAAQPcQoiOUSoXCPsdEAwAAAEBlIkRHKJUKm5NKNAAAAABUJkJ0hHKVaI6JBgAAAIDKRIiOUDpNJRoAAAAAKhkhOkLJZBhYLB7nFFcAAAAAUIkI0RHKV6IJ0QAAAABQiQjREeIUVwAAAABQ2QjREUomw+aMxahEAwAAAEBUzOw0M1tiZkvN7POdzPMuM3vOzBaZ2W2lakuiVCveG+Uq0VVVyTK3BAAAAAAqg5nFJf1I0qmSVkl60szucvfnCuaZIulySce5+2YzG12q9lCJjlAqxcBiAAAAABCxWZKWuvsyd2+V9CtJZ7eb56OSfuTumyXJ3deVqjGE6AilUiZJisc5JhoAAAAAIjJO0sqC66uy0wodJOkgM3vEzB43s9NK1Ri6c0eIgcUAAAAAoEcSZja34PoN7n5Dd5aXNEXSiZLGS3rIzI5w9y3RNTF/R4hIbmAxKtEAAAAA0C0pd5/ZyW2rJU0ouD4+O63QKkn/cvekpOVm9m+FUP1k1A2lO3eE8ueJJkQDAAAAQESelDTFzCaZWbWk8yTd1W6ePyhUoWVm+yh0715WisYQoiPEMdEAAAAAEC13T0m6RNK9khZLusPdF5nZV83srOxs90raaGbPSfqbpM+6+8ZStIfu3BFKZbNzLEaIBgAAAICouPs9ku5pN+1LBf93SZdlLyVFJTpCuRDNeaIBAAAAoDIRoiOUzGZnKtEAAAAAUJkI0RHKVaITCSrRAAAAAFCJCNERylWiGVgMAAAAACoTITpCuUo0IRoAAAAAKhMhOkL5EN1a3oYAAAAAAEqCEB2hXHfuRIJKNAAAAABUIkJ0hKhEAwAAAEBlI0RHKH+KK0bnBgAAAIBKRIiOEKe4AgAAAIDKRoiOEN25AQAAAKCyEaIjlO/OnS5vQwAAAAAAJUGIjlAqJSUSrZII0QAAAABQiQjREUompXg8LfdMuZsCAAAAACgBQnSEQiU6JSrRAAAAAFCZCNERohINAAAAAJWNEB2hUIlOy51KNAAAAABUIkJ0hOjODQAAAACVjRAdIbpzAwAAAEBlI0RHiO7cAAAAAFDZCNERylWiJSrRAAAAAFCJCNERSqVy3bmpRAMAAABAJSJERyiVkqqqqEQDAAAAQKUiREcoP7AYlWgAAAAAqESE6AjlBxajEg0AAAAAlYgQHaFkUkokMuI80QAAAABQmQjREQoDi2Xozg0AAAAAFYoQHSG6cwMAAABAZSNER4ju3AAAAABQ2QjREaISDQAAAACVjRAdoXCKK46JBgAAAIBKRYiOUKhEuyQq0QAAAABQiQjREcp356YSDQAAAACViBAdofzAYlSiAQAAAKASEaIjFCrRHBMNAAAAAJWKEB2hUIl2QjQAAAAAVChCdIRylWi6cwMAAABAZSJER4ju3AAAAABQ2QjREcp356YSDQAAAACViBAdoXx3birRAAAAAFCJCNERyWTCJZEQlWgAAAAAqFCE6IikUuEvx0QDAAAAQOUiREckmQx/EwkXo3MDAAAAQGUiREckX4nmPNEAAAAAUKkI0RHJheiqKirRAAAAAFCpCNERKezOTSUaAAAAACoTIToidOcGAAAAgMpHiI4IA4sBAAAAQOUjREckX4kOfzlXNAAAAABUHkJ0RPIDi4W/hGgAAAAAqDyE6Ii07c4tSRwXDQAAAACVhhAdESrRAAAAAFD5CNERyVWi4/FQiWaEbgAAAACoPIToiOQr0ZadQiUaAAAAACoNIToiheeJlqhEAwAAAEAlIkRHJD+wWKhEE6IBAAAAoPIQoiOS786dG52b7twAAAAAUGkI0RGhEg0AAAAAlY8QHZH8MdG5KVSiAQAAAKDSEKIjkgvR1dXhL5VoAAAAAKg8hOiI5M8TnevOTSUaAAAAACoNIToi7SvREpVoAAAAAKg0hOiI7D6wGJVoAAAAAKg0hOiI5E9xFf5yTDQAAAAAVB5CdETyo3PnNikhGgAAAAAqDSE6Ivnu3OEv3bkBAAAAoPIQoiOS786dOyaaSjQAAAAAVBpCdERylehciJaoRAMAAABApSFER4RKNAAAAABUvkQ57tTMXpK0XWH0rZS7zyxHO6KUq0TH4/HsFCrRAAAAAFBpyhKis05y9w1lvP9IpVJhULFYLBT3qUQDAAAAQOWhO3dEUqncOaJDJZrRuQEAAAAgGmZ2mpktMbOlZvb5Dm7/gJmtN7NnspePlKot5apEu6T7zMwl/cTdbyhTOyKTTIZKtBnniQYAAACAqJhZXNKPJJ0qaZWkJ83sLnd/rt2sv3b3S0rdnnKF6Ne7+2ozGy3pfjN73t0fKpzBzGZLmi1J1dXV5Whjt+Qq0WH/0p0bAAAAACIyS9JSd18mSWb2K0lnS2ofovtEWbpzu/vq7N91kn6vsFHaz3ODu89095mJRDkP3S5OrhKd26R05wYAAACASIyTtLLg+qrstPbebmYLzOxOM5tQqsb0eYg2s3oza8j9X9KbJD3b1+2IWm5gsVwlmu7cAAAAAFC0hJnNLbjM7ubyf5K0v7tPk3S/pJujb2JQjhLvGEm/N7Pc/d/m7n8tQzsilR9YjEo0AAAAAHRTV6c+Xi2psLI8PjttF3ffWHD1Z5L+N9rm5fV5iM72Yz+yr++31PIDi3FMNAAAAABE6ElJU8xskkJ4Pk/S+YUzmNlYd1+TvXqWpMWlakz/P9h4gGg/sJhEJRoAAAAAesvdU2Z2iaR7Fc4pfJO7LzKzr0qa6+53SbrUzM6SlJK0SdIHStUeQnREdh9YjEo0AAAAAETB3e+RdE+7aV8q+P/lki7vi7aUZXTuSrT7wGJUogEAAACg0hCiI5Lvzk0lGgAAAAAqFSE6Ivnu3AwsBgAAAACVihAdESrRAAAAAFD5CNERyVWiE4nhkqRUanOZWwQAAAAAiBohOiK5gcWqqkZKiqu19dVyNwkAAAAAEDFCdEQKu3NXV48hRAMAAABABSJERyQ/sJhUXT1Wra1rytsgAAAAAEDkCNERyVWiJam6el8q0QAAAABQgQjREWlbiSZEAwAAAEAlIkRHZPdK9DpOcwUAAAAAFYYQHZHc6NxSCNFSWsnkxrK2CQAAAAAQLUJ0RNp355ZEl24AAAAAqDCE6Ii0784tEaIBAAAAoNIQoiNSWImuqRkrSZzmCgAAAAAqDCE6IoWV6KqqMZKoRAMAAABApSFER6SwEp1IDFY8PpgQDQAAAAAVhhAdkcLRuSXOFQ0AAAAAlYgQHYFMJlxy3bklQjQAAAAAVCJCdARSqfCXSjQAAAAAVDZCdARyIZpKNAAAAABUNkJ0BJLJ8LdtJXqsUqktSqebytMoAAAAAEDkCNER6Kw7tyS1tq4tQ4sAAAAAAKVAiI5AZ925Jc4VDQAAAACVhBAdgY67cxOiAQAAAKDSEKIjQCUaAAAAAPYOhOgIdFSJrqoaJckI0QAAAABQQQjREehoYLFYrEpVVfsQogEAAACgghCiI9BRd24pnOaqtXVN3zcIAAAAAFAShOgIdNSdWwrHRVOJBgAAAIDKQYiOQOeVaEI0AAAAAFQSQnQE9lSJdve+bxQAAAAAIHKE6Ah0NLCYFEK0e6tSqS193iYAAAAAQPQI0RHoqju3xLmiAQAAAKBSEKIj0FV3bokQDQAAAACVghAdga5OcSWJ01wBAAAAQIUgREeASjQAAAAA7B0I0RHorBKdSAyVWQ0hGgAAAAAqBCE6Ap2Nzm1mnCsaAAAAACoIIToCnXXnlkSIBgAAAIAKQoiOQGfduSVCNAAAAABUEkJ0BKhEAwAAAMDegRAdgT1VopPJ9cpkkn3bKAAAAABA5AjREeiqEl1TMzY7z7o+bBEAAAAAoBQI0b01b55S3/6upM67c0ucKxoAAAAAKgEhureGD1dqdQjInXXnlgjRAAAAAFAJCNG9tf/+StYOkdR1JbqlZU1ftgoAAAAAUAKE6N4yU2rseElSPL77zdXVr1EsVq8dO+b1ccMAAAAAAFEjREcgOWa8EkrKkq273RaLVWn48JO0adO9ZWgZAAAAACBKhOgIpEa9RgmlpEWLOrx9+PA3q7l5mZqaXuzjlgEAAAAAokSIjkBqn31VpaT01FMd3j5ixJskiWo0AAAAAAxwhOgIJAcNVcLS0ryOj3uuq5ui2tr9tWnTfX3cMgAAAABAlAjREUilTVUJ77QSbWYaPvzN2rLlQWUyyT5uHQAAAAAgKoToCCSTUqImLs2fH650YMSINymd3q5t2x7v49YBAAAAAKJCiI5AKiUlahNSS4u0eHGH8wwb9kZJcY6LBgAAAIABjBAdgVRKqhpUFa500qW7qmqYhgw5Rps3c1w0AAAAAAxUhOgIJJNSoq5KamjoNERL0ogRb9b27XPV2rqhD1sHAAAAAIgKIToCqZRUVWXSUUd1OkK3JA0f/iZJri1bHui7xgEAAAAAIkOIjkAyKSUSkmbMkJ55JqTqDgwZcrQSiWEcFw0AAAAAAxQhOgKpVDZEv/a1UlOT9PzzHc5nFtfw4ado06Z75e5920gAAAAAQK8RoiMQunMrhGhpD12636zW1lfU2Phc3zQOAAAAABAZQnQEdnXnPuggqb5+D4OLvUmStGHDH/qmcQAAAACAyBCiI7CrEh2PS9Ond1mJrq3dTyNGnKaXX75aLS2r+6yNAAAAAIDeI0RHYFclWgqDiz39tJROdzr/lCk/kntSL7zwyb5pIAAAAAAgEoToCOyqREvhuOidO6V//7vT+evqJmvixC9pw4bfasOGP/VNIwEAAAAAvUaIjsCu0bml/OBic+d2ucyECZ/RoEGH6YUXLlE6vbO0DQQAAAAARIIQHYE23bkPPVQaMkR65JEul4nFqnXwwT9RS8vLeumlq0reRgAAAABA7xGiI9CmO3c8Lh177B5DtCQNHXqcxo6drZUrr9X27c+UtI0AAAAAgN4jREegTSVakl7/eunZZ6XNm/e47OTJ31RV1XC99NKVpWsgAAAAACAShOgItKlES9Jxx4W/jz66x2WrqobrNa+5UBs3/llNTS+VpH0AAAAAgGgQoiOwWyV61qww4eGHi1p+7NjZkkxr1txQkvYBAAAAAKJBiI5Am9G5JWnQoDBKdxHHRUtSbe0EjRz5Vq1Zc6MymZbSNBIAAAAABigzO83MlpjZUjP7fBfzvd3M3MxmlqothOgI7NadWwpdup94QmopLhSPG3eRksl1Wr/+d9E3EAAAAAAGKDOLS/qRpNMlTZX0HjOb2sF8DZI+KelfpWwPIToCu3XnlsLgYi0t0lNPFbWO4cNPVW3tAXrllR9H30AAAAAAGLhmSVrq7svcvVXSrySd3cF8X5N0taTmUjaGEB2BTivRUtHHRZvF9JrXXKitWx/Wjh0Lo20gAAAAAAxc4yStLLi+KjttFzObIWmCu/+51I0hREegw0r06NHSlClFHxctSWPHflBmNXrlleuibSAAAAAA9G8JM5tbcJld7IJmFpP0HUmfKV3z8gjRvZTJhMtuIVoKXbofeSTMUISqqpEaPfrdWrv2F0qltkfbUAAAAADov1LuPrPgUnjqotWSJhRcH5+dltMg6XBJfzezlyT9h6S7SjW4GCG6l9Lp8He37txSCNEbN0pLlhS9vnHjPq50eodWrvy2MpnWaBoJAAAAAAPXk5KmmNkkM6uWdJ6ku3I3uvtWd9/H3fd39/0lPS7pLHefW4rGEKJ7KZkMfzutREvd6tLd0DBLw4adpBUrvqpHH91XS5bM1ubNf5d7cdVsAAAAAKgk7p6SdImkeyUtlnSHuy8ys6+a2Vl93R5z976+z26rr6/3nTt3lrsZHdq2TRo6VLrmGumyy9rd6C6NGSOdcYb0858Xvc5MJqnNm+do3brbtH7975XJ7NSgQYfowAO/qxEj3hxp+wEAAACg3Mys0d3ry92OYlCJ7qUuK9FmYZTuIkfozonFqjRy5Ok69NBf6Ljj1unQQ2+Ve0oLFpymhQvfqsbGF3rfcAAAAABAtxGieymVCn87DNFS6NL94ovSq6/2aP3x+CCNGXO+jj76WU2e/L/asuUfevLJw/Tii/+tVGpbzxoNAAAAAOgRQnQv5UJ0hwOLSfnzRf/856F7dw/FYjXab7/Patasf2vMmPdr5cpv61//mqI1a27q9Hhp94yaml7U+vW/06uv/qLLgcpSqR09bhsAAAAA7C04JrqXXnpJmjRJuukm6YMf7GCGZFI64QTpscekWbOkb39bOv74Xt/vtm1ztXTpJ7Vt26MaPPi1GjfuYqVSW9Taukatra+qqWmZdu5coHQ6f6qsQYOm6qCDfqJhw16/a9qOHc9q+fLLtXHj3aqvP1JjxrxHo0efp9raib1uI7onnd6pbdue0LBhJ8rMyt0cAAAAoM8MpGOiCdG9tHSpNGWK9ItfSO97XyczpdPSL38pfeEL0urV0jnnhJHIJk3q1X27u9at+5VefPGzam0Np0kzq1Z19VjV1u6n+vppGjx4ugYPnq7W1jV64YVPqKVlhcaO/YjGjbtUq1Zdq1dfvVnxeIP23fcD2rbtcW3f/i9J0tChr9fEiV9kILM+kk43acGC07V16z80ZswFOvjgGxSLVZe7WQAAAECfIETv6U7NTpP0PUlxST9z9292NX9/DtGLF0tTp0q33y6dd94eZm5slK69VvrmN8OgYz/4gfSf/xn+3wvpdJOam1eounqMEolhnVYx0+mdeumlr2jlyu9ISsusWuPGXaKJE69QVdVISVJT04tat+5XWrPmRjU3L9eIEafpgAOuUX391N3W5+5qaXlZ27Y9oe3b58o9pURiiOLxIUokhqq+fpoaGmbIjKMGupLJJLVo0bnauPHPGjXqnVq//g4NHXqCDj/8t7v2CwAAAFDJCNFd3aFZXNK/JZ0qaZXCibPf4+7PdbZMfw7RCxdK06ZJd94pvf3tRS60YkUIzw89JL3zndL110sjRpS0nYV27JivjRv/rNGjz1dd3f4dzpPJtGj16h/ppZe+qnR6h8aO/bBqa/dXMrleyeQGtbau1Y4dzyiZXCcpVMDNqpTJtN1P1dWv0ciRb9U++5ylwYOnKxarUyxWq1istqguy62t67V58xxt3nyfmptXqKFhpoYMOVZDhx6r6urRvd4W5eae1uLF79e6dbdrypTrNG7chVq79jY9//wHVVs7UUcc8WcNGjSl3M0EsAfurmRyneLxwYrHB8TnPwAA/Qohuqs7NHudpKvc/c3Z65dLkrt/o7Nl+nOIfvppacYM6Q9/kM4+uxsLptPh+Ogrr5RGjZIuuUQ68EDpgAPCZejQUjW5W1pbN2jFiq9o9errJKUVi9WrunqUqqr2UX394WpomKUhQ2apvv4IxWLVymRSSqe3K5XarK1bH9aGDXdp8+Z7lU7vPnBZPD5YicRIVVWNVFXVCMXjgyXlg3Vz88vasWOeJFciMUJ1dZO1Y8cCuYcB0mpqxiseH6p4vF7x+CDFYoMUj9dn/w5SPD5Y1dX7qqZmnKqrx6m6et9edpF2pdONSqW2KpXaonR6q8wSqqoatesSvjxn5J6We0ZmCcXj9R3+YODueuGFj+uVV67X5Mnf1H77fW7XbVu3PqJnn32bMplmDR48Q3V1B6iu7gDV1h6w6/9VVfkfXtLpnWpqelHNzSsUi9WpunqMqqtHq6pqn1235y6ZzM42180SSiQaFI8PUTzekO1N0NDhDx3h/cJ71LsgnW5Wc/MytbauUVXVKNXUjFciMbzPjv92T2fHClikdHq7ampeo+rqcaqpGadEoqFP2oDSc8+osfHf2r79CTU1LdWgQYeooWGm6uoOjKxXTEvLam3d+rC2bn1EjY3Pq7l5hVpaXlYm06xYrFYjRpyuUaPeqZEj31LUcyuTaVFT04tqbHxeyeQm1dcfpvr6I5RIDI6kvags7hklkxskxVRVNZIxNAYod1c6vU2treuVTm/fdZFMdXVTVFs7SbFYZ6d+ya8jk2mUZAo1qrjM4jwnMGARoru6Q7N3SDrN3T+Svf5+Sce4+yWdLdOfQ/QTT0jHHCPdfbd05pk9WMG8edKHPiTNn992+qBB0rBh0vDh4VJdLbW0SK2t4W86HbqB5y6xWNvrHU1Lp8MlkwkjhdfWhktdnVRTE+bvRMZTsl1v0t0TPvDXK51pzIbLtORpuaeU8VZ5pkUZT8o91Wa5mFWrqnq0qqtGK1E1XCaTe1qp1BYlkxuVSm+Teyosl12ve0qu3P+Tex4RvY8+Z8yqZLEqmWL5dnpKkqtu0MEaXH/4bsuk0zu1s/F5pdPblUnvVCbTvNs6Y/FBymSa5ZmWotviRT7msL8TkmJypSXPyBVGgo9ZtSxWHf5aPDwmZcJ+UEaW/SCXxRV+fNi9/eE+YorF6rLzxmSKSRbL7rdwcfmu9uSW2rXjsl8U2t6WX3u4aspkmpVOb+t0JHuzeNg/Vq1YrDr7uHMbrKPnkBf8G/6X26fuSbmns19kqsJ+skR23ky2DYXtyLfd2jyuwum5x1P4OD27T8LfMDmWfY3Gsq1KyTOtu9oky91HbNf6LLc9zcL233U/ln3s6V1tDp8XBY/B4opZlcwSMqtqt/3zjzc8f9La9UXP4jLl3kva7+dY9rlgHayv49dzbln3lFLJTbu9l4RNmsge7pLbt7l1F7Yxk90O8exjyr/fhe3syjRuke1oUrxJSjSZLF4jH1wnDW6QNQxVKt6klpZV4fluMSUSQ/P7a9dDKHjmeFLpdMefb6Gq3ZDdj0m5t2YfWyz7g0A8/LW4TLFdr6M+e2NT4WuvfLyT58WelurqqqRd7x/5eTLh3na9hgtfOwWvTWv73O14G3X0w2pSmUyzMpkWZbxVkikWq1HMqhWL1cg9rUymSelMU8FrPq54rE6x+CDFrKsfiYvbRj3blm31/DlRzHK+6/tC+OzPFLwG4l18R9nTuju53Tq74m3+7Da9i2nuqfCZlGnOvi921iRTPN6geKy+3WF/Hp4jmebwPtPB55pZQharyr4/V2W3T+55WfDel31fyz3X27zvZp/Hue9e4fta+DwJP6ZXZ++j3Wdmn+juc6zz53Xnz3nv8L9drS98Dwqfk2Getu/R4fbMrr+F31Pa7B/Lb3f3VmWy3y0ka/uZu8cfhts99wYP0vA7l+5hmfIaSCG6r5/1RTOz2ZJmS1J1df8dYKm6WjrkEGnIkB6uYMYM6ZlnpO3bpWXLwjmlX3xRWrtW2rw5f2luDkG3oSH8jcfDC7XwkgvHnU2Lx/MXKYTxpiZp/fqw/i70pn5jkqp3m5LIXmqLWMOG7CUsWZW9SF1v9PBdNd32A7fNm2L3vyyEL/jhTdEUz34A5UNxPgiEf3MBJxfsJZcpIVld+NIbq1EikZD0/G73FZc0RPWS6rOPJ6NMJin3FnmmNfuBlpJZnSw2dFewlWcr4co95uybs8Ukj2V/oc59CY8pH8Yy2TbmQ5Lv+oDPrcOymy73Y0iLXF5wWyzbcpc8KVcI9zGrkcUadn3YutLyTLLgg8Gl7P4J27AgOO7Gd/u3/W3tr5viitkwWawmW2GPyTO5wJvbd9nH6427fizo6BnQmXyoqVUuNIXt1yL3pl1bsf0X7N3a7d15fLkvOblb8z8+yAsCqcWVf7vPffnLbeuM2q7X86+N3cK8ZX8YSWSn554jSbnvHgTDd4NcqMutp7Xgvl35V4vt/hg61dl+MMVig0OoiNXKYtXhtZJpVjrTJM/sbPeFKffcLWyjZ9vXfrtk1dbKhoxVfNS+SgwdG5bfvl3asUN6dbvUmtBg7a9MplHp1PZsGOr8MYT3gZGKxWqyh8XEC74gt8h9U8H7TkL5d9NMtp1pSdn3ttyPKuihDkJSu9vzPzoVzpZ7tXrhxC50dnss++W4RmaDsi/jdPZ9qjn7XEnIbFj2Rytlf1xJyn1bF+9bHT2+/qbY563tel/LfY6Fz6vw+dr2c73jd9FStKn4ObIByRIyDQ37U7kfkXM/gnn2M75FmUyr3Dftvj5LZC/DCn6QLHj/bPOZ3lTwudLx+27bR93R8zj8ABq2fV12Wib7w16TerOVu6+n99Xb538x+7nw/aHdj927tnvb71P556x38IzNFa9isuyPZG0/c7u3LTJD+mdBcqCiOzcAAAAAoKwGUiW6HMMmPylpiplNsvCzynmS7ipDOwAAAAAA6JY+787t7ikzu0TSvQr9Pm9y90V93Q4AAAAAALqrLOeJ7i66cwMAAABA5aI7NwAAAAAAFYgQDQAAAABAkQjRAAAAAAAUiRANAAAAAECRCNEAAAAAABSJEA0AAAAAQJEI0QAAAAAAFIkQDQAAAABAkQjRAAAAAAAUiRANAAAAAECRCNEAAAAAABSJEA0AAAAAQJEI0QAAAAAAFIkQDQAAAABAkQjRAAAAAAAUiRANAAAAAECRCNEAAAAAABSJEA0AAAAAQJEI0QAAAAAAFIkQDQAAAABAkczdy92GPTKzjKSmcrdjDxKSUuVuBNpgn/RP7Jf+if3SP7Ff+if2S//Efumf2C/9U3/cL3XuPiCKvAMiRA8EZjbX3WeWux3IY5/0T+yX/on90j+xX/on9kv/xH7pn9gv/RP7pXcGRNIHAAAAAKA/IEQDAAAAAFAkQnR0bih3A7Ab9kn/xH7pn9gv/RP7pX9iv/RP7Jf+if3SP7FfeoFjogEAAAAAKBKVaAAAAAAAikSI7iUzO83MlpjZUjP7fLnbs7cyswlm9jcze87MFpnZJ7PTrzKz1Wb2TPZyRrnburcxs5fMbGF2+8/NThthZveb2QvZv8PL3c69iZkdXPCaeMbMtpnZp3i99D0zu8nM1pnZswXTOnx9WPD97OfNAjObUb6WV7ZO9su3zOz57Lb/vZkNy07f38yaCl4315et4RWuk/3S6fuWmV2efb0sMbM3l6fVla+T/fLrgn3ykpk9k53O66WPdPHdmM+YCNCduxfMLC7p35JOlbRK0pOS3uPuz5W1YXshMxsraay7zzOzBklPSXqbpHdJ2uHu3y5n+/ZmZvaSpJnuvqFg2v9K2uTu38z++DTc3T9XrjbuzbLvY6slHSPpg+L10qfM7A2Sdki6xd0Pz07r8PWRDQefkHSGwv76nrsfU662V7JO9subJD3o7ikzu1qSsvtlf0l35+ZD6XSyX65SB+9bZjZV0u2SZkl6jaQ5kg5y93SfNnov0NF+aXf7NZK2uvtXeb30nS6+G39AfMb0GpXo3pklaam7L3P3Vkm/knR2mdu0V3L3Ne4+L/v/7ZIWSxpX3lahC2dLujn7/5sV3tRRHidLetHdV5S7IXsjd39I0qZ2kzt7fZyt8CXV3f1xScOyX5IQsY72i7vf5+6p7NXHJY3v84bt5Tp5vXTmbEm/cvcWd18uaanC9zZErKv9YmamUNC4vU8bha6+G/MZEwFCdO+Mk7Sy4PoqEdzKLvsr51GS/pWddEm2W8pNdBsuC5d0n5k9ZWazs9PGuPua7P9flTSmPE2DpPPU9ssNr5fy6+z1wWdO//EhSX8puD7JzJ42s3+Y2fHlatRerKP3LV4v/cPxkta6+wsF03i99LF23435jIkAIRoVxcwGS/qtpE+5+zZJ10k6QNJ0SWskXVO+1u21Xu/uMySdLunibLevXTwcU8JxJWVgZtWSzpL0m+wkXi/9DK+P/sfMviApJenW7KQ1kvZz96MkXSbpNjMbUq727YV43+rf3qO2P9TyeuljHXw33oXPmJ4jRPfOakkTCq6Pz05DGZhZlcKbxK3u/jtJcve17p5294ykn4quXH3O3Vdn/66T9HuFfbA210Uo+3dd+Vq4Vztd0jx3XyvxeulHOnt98JlTZmb2AUlvkfTe7JdPZbsLb8z+/ylJL0o6qGyN3Mt08b7F66XMzCwh6VxJv85N4/XStzr6biw+YyJBiO6dJyVNMbNJ2YrOeZLuKnOb9krZY25ulLTY3b9TML3wWI5zJD3bflmUjpnVZwezkJnVS3qTwj64S9IF2dkukPTH8rRwr9emQsDrpd/o7PVxl6T/zI6g+h8KA/Ws6WgFiJ6ZnSbpvyWd5e6NBdNHZQfok5lNljRF0rLytHLv08X71l2SzjOzGjObpLBfnujr9u3lTpH0vLuvyk3g9dJ3OvtuLD5jIpEodwMGsuwInZdIuldSXNJN7r6ozM3aWx0n6f2SFuZOoyDpCknvMbPpCl1VXpL0sXI0bi82RtLvw/u4EpJuc/e/mtmTku4wsw9LWqEw6Aj6UPZHjVPV9jXxv7xe+paZ3S7pREn7mNkqSV+W9E11/Pq4R2HU1KWSGhVGU0cJdLJfLpdUI+n+7Hva4+5+oaQ3SPqqmSUlZSRd6O7FDn6Fbuhkv5zY0fuWuy8yszskPafQ/f5iRuYujY72i7vfqN3H3JB4vfSlzr4b8xkTAU5xBQAAAABAkejODQAAAABAkQjRAAAAAAAUiRANAAAAAECRCNEAAAAAABSJEA0AAAAAQJEI0QAADEBmdqKZ3V3udgAAsLchRAMAAAAAUCRCNAAAJWRm7zOzJ8zsGTP7iZnFzWyHmV1rZovM7AEzG5Wdd7qZPW5mC8zs92Y2PDv9QDObY2bzzWyemR2QXf1gM7vTzJ43s1vNzMr2QAEA2EsQogEAKBEzO1TSuyUd5+7TJaUlvVdSvaS57n6YpH9I+nJ2kVskfc7dp0laWDD9Vkk/cvcjJR0raU12+lGSPiVpqqTJko4r8UMCAGCvlyh3AwAAqGAnS3qtpCezReI6SeskZST9OjvPLyX9zsyGShrm7v/ITr9Z0m/MrEHSOHf/vSS5e7MkZdf3hLuvyl5/RtL+kh4u+aMCAGAvRogGAKB0TNLN7n55m4lmV7abz3u4/paC/6fF5zoAACVHd24AAErnAUnvMLPRkmRmI8xsosLn7zuy85wv6WF33ypps5kdn53+fkn/cPftklaZ2duy66gxs0F9+SAAAEAev1gDAFAi7v6cmX1R0n1mFpOUlHSxpJ2SZmVvW6dw3LQkXSDp+mxIXibpg9np75f0EzP7anYd7+zDhwEAAAqYe097kAEAgJ4wsx3uPrjc7QAAAN1Hd24AAAAAAIpEJRoAAAAAgCJRiQYAAAAAoEiEaAAAAAAAikSIBgAAAACgSIRoAAAAAACKRIgGAAAAAKBIhGgAAAAAAIr0/wFF167iL0Y1dQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1152x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, loss_ax = plt.subplots(figsize=(16, 10))\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(history.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(history.history['val_loss'], 'r', label='val loss')\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "loss_ax.legend(loc='upper left')\n",
    "\n",
    "acc_ax.plot(history.history['acc'], 'b', label='train acc')\n",
    "acc_ax.plot(history.history['val_acc'], 'g', label='val acc')\n",
    "acc_ax.set_ylabel('accuracy')\n",
    "acc_ax.legend(loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[82,  0],\n",
       "        [ 0, 22]],\n",
       "\n",
       "       [[76,  0],\n",
       "        [ 0, 28]],\n",
       "\n",
       "       [[73,  0],\n",
       "        [ 0, 31]],\n",
       "\n",
       "       [[81,  0],\n",
       "        [ 0, 23]]], dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model('models/multi_hand_gesture_classifier.h5')\n",
    "\n",
    "y_pred = model.predict(x_val)\n",
    "\n",
    "multilabel_confusion_matrix(np.argmax(y_val, axis=1), np.argmax(y_pred, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\user\\AppData\\Local\\Temp\\tmp8mcf3kjg\\assets\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# Convert the model.\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the model.\n",
    "with open('models/multi_hand_gesture_classifier.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "eb8d34d53d16442ab45ee5ae0fcb3a4f0af0f2ef684aa754f8ae5e8bd03f8c50"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('mp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
